{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "\n",
    "Improvements include:\n",
    "    - Configurable noise filtering using wavelet transform and FFT (plus additional SMA feature).\n",
    "    - An improved trading environment with risk management (transaction cost & slippage) and expanded observation space.\n",
    "    - Basic logging for better traceability.\n",
    "    - More robust hyperparameter evaluation (averaging over episodes).\n",
    "    - Modular design for easier maintenance.\n",
    "    \n",
    "Required packages:\n",
    "    numpy, pandas, matplotlib, gym, torch, pywavelets, scipy, stable-baselines3, bayesian-optimization, deap, requests\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "from gym import spaces\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pywt  # For wavelet transforms\n",
    "from scipy.fft import fft, ifft\n",
    "from stable_baselines3 import PPO\n",
    "from bayes_opt import BayesianOptimization\n",
    "from deap import base, creator, tools, algorithms\n",
    "import random\n",
    "import requests\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s: %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "\n",
    "def load_data(cache_file=\"binance_data.csv\", symbol='BTCUSDT', interval='1m', limit=5000, max_retries=3):\n",
    "    \"\"\"\n",
    "    Load data from Binance API with caching and robust error handling.\n",
    "    If cache_file exists, load data from it.\n",
    "    \"\"\"\n",
    "    if os.path.exists(cache_file):\n",
    "        logger.info(\"Loading data from cache file: %s\", cache_file)\n",
    "        data = pd.read_csv(cache_file, parse_dates=['timestamp'], index_col='timestamp')\n",
    "        return data\n",
    "\n",
    "    url = \"https://api.binance.com/api/v3/klines\"\n",
    "    params = {\n",
    "        'symbol': symbol,\n",
    "        'interval': interval,\n",
    "        'limit': limit\n",
    "    }\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            response = requests.get(url, params=params, timeout=10)\n",
    "            if response.status_code == 200:\n",
    "                data_json = response.json()\n",
    "                data = pd.DataFrame(\n",
    "                    data_json,\n",
    "                    columns=['timestamp', 'open', 'high', 'low', 'close', 'volume', \n",
    "                             'close_time', 'quote_asset_volume', 'number_of_trades', \n",
    "                             'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore']\n",
    "                )\n",
    "                data = data[['timestamp', 'open', 'high', 'low', 'close', 'volume']]\n",
    "                data['timestamp'] = pd.to_datetime(data['timestamp'], unit='ms')\n",
    "                data.set_index('timestamp', inplace=True)\n",
    "                data = data.astype(float)\n",
    "                data = data.rename(columns={'open':'Open', 'high':'High', 'low':'Low', 'close':'Close', 'volume':'Volume'})\n",
    "                data.to_csv(cache_file)\n",
    "                logger.info(\"Data fetched and cached to %s\", cache_file)\n",
    "                return data\n",
    "            else:\n",
    "                logger.error(\"Error fetching data: %s, %s\", response.status_code, response.text)\n",
    "        except Exception as e:\n",
    "            logger.error(\"Exception occurred: %s\", e)\n",
    "        retries += 1\n",
    "        time.sleep(2)\n",
    "    raise Exception(\"Failed to load data after several retries.\")\n",
    "\n",
    "\n",
    "def noise_filtering(data, wavelet='db1', level=2, fft_cutoff=0.1, plot=True):\n",
    "    \"\"\"\n",
    "    Apply noise filtering to the 'Close' price using wavelet transform and FFT.\n",
    "    Also calculates a Simple Moving Average (SMA) for additional features.\n",
    "    \"\"\"\n",
    "    signal = data['Close'].values\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.subplot(3, 1, 1)\n",
    "        plt.plot(data['Close'], label='Original Signal', color='blue')\n",
    "        plt.title('Original Close Price')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Close Price')\n",
    "        plt.legend()\n",
    "\n",
    "    # Wavelet decomposition using the specified wavelet and level\n",
    "    coeff = pywt.wavedec(signal, wavelet, level=level)\n",
    "    sigma = np.median(np.abs(coeff[-1])) / 0.6745\n",
    "    uthresh = sigma * np.sqrt(2 * np.log(len(signal)))\n",
    "    coeff_filtered = [pywt.threshold(c, value=uthresh, mode='soft') for c in coeff]\n",
    "    filtered_signal = pywt.waverec(coeff_filtered, wavelet)\n",
    "\n",
    "    # FFT filtering: remove high-frequency components\n",
    "    fft_coeff = fft(filtered_signal)\n",
    "    freq = np.fft.fftfreq(len(filtered_signal))\n",
    "    fft_coeff[np.abs(freq) > fft_cutoff] = 0\n",
    "    filtered_signal_fft = np.fft.ifft(fft_coeff).real\n",
    "\n",
    "    if plot:\n",
    "        plt.subplot(3, 1, 2)\n",
    "        plt.plot(filtered_signal, label='Filtered Signal (Wavelet)', color='green')\n",
    "        plt.title('Filtered Signal using Wavelet')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Price')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(3, 1, 3)\n",
    "        plt.plot(filtered_signal_fft, label='Filtered Signal (FFT)', color='red')\n",
    "        plt.title('Filtered Signal using FFT')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Price')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    data['Close_filtered'] = filtered_signal_fft\n",
    "\n",
    "    # Compute Simple Moving Average (SMA) with window=5 as an additional feature\n",
    "    data['SMA'] = data['Close_filtered'].rolling(window=5, min_periods=1).mean()\n",
    "    # Calculate RSI\n",
    "    delta = data['Close'].diff(1)\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "    avg_gain = gain.rolling(window=14, min_periods=1).mean()\n",
    "    avg_loss = loss.rolling(window=14, min_periods=1).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    data['RSI'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # Calculate Bollinger Bands\n",
    "    sma_20 = data['Close'].rolling(window=20).mean()\n",
    "    std_20 = data['Close'].rolling(window=20).std()\n",
    "    data['Bollinger_Upper'] = sma_20 + 2 * std_20\n",
    "    data['Bollinger_Lower'] = sma_20 - 2 * std_20\n",
    "    \n",
    "    # Calculate Volatility (ATR)\n",
    "    high_low = data['High'] - data['Low']\n",
    "    high_close = np.abs(data['High'] - data['Close'].shift())\n",
    "    low_close = np.abs(data['Low'] - data['Close'].shift())\n",
    "    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
    "    data['ATR'] = tr.rolling(window=14).mean()\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    \"\"\"\n",
    "    Hybrid feature extraction model combining CNN, LSTM, and Transformer Encoder.\n",
    "    Although not directly integrated in the TradingEnv, this model can be used\n",
    "    to extract predictive features from time-series data.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, cnn_channels, lstm_hidden_size, transformer_dim, nhead, num_transformer_layers):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        # CNN for local feature extraction (1D convolution)\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=input_dim, out_channels=cnn_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=cnn_channels, out_channels=cnn_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # LSTM for capturing sequential dependencies\n",
    "        self.lstm = nn.LSTM(input_size=cnn_channels, hidden_size=lstm_hidden_size, batch_first=True)\n",
    "        # Fully connected layer to map LSTM output to transformer dimension\n",
    "        self.fc = nn.Linear(lstm_hidden_size, transformer_dim)\n",
    "        # Transformer Encoder for global dependency modeling\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=transformer_dim, nhead=nhead)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_transformer_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Rearrange for CNN: (batch, features, seq_len)\n",
    "        x_cnn = x.transpose(1, 2)\n",
    "        cnn_out = self.cnn(x_cnn)\n",
    "        # Rearrange back: (batch, seq_len, channels)\n",
    "        cnn_out = cnn_out.transpose(1, 2)\n",
    "        # LSTM processing\n",
    "        lstm_out, _ = self.lstm(cnn_out)\n",
    "        # Map LSTM output to transformer dimension\n",
    "        fc_out = self.fc(lstm_out)\n",
    "        # Transformer expects input shape: (seq_len, batch, d_model)\n",
    "        transformer_in = fc_out.transpose(0, 1)\n",
    "        transformer_out = self.transformer(transformer_in)\n",
    "        # Aggregate transformer outputs (mean over sequence length)\n",
    "        features = transformer_out.mean(dim=0)\n",
    "        return features  # Shape: (batch, transformer_dim)\n",
    "\n",
    "\n",
    "class TradingEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Custom trading environment for simulating BTC/USD trading with risk management and additional features.\n",
    "    Observations: Sliding window of normalized filtered closing prices and SMA.\n",
    "    Actions: 0 = Hold, 1 = Buy, 2 = Sell.\n",
    "    Reward: Profit/loss realized after accounting for transaction costs and slippage.\n",
    "    \"\"\"\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, data, window_size=20, transaction_cost=0.001, slippage=0.001):\n",
    "        super(TradingEnv, self).__init__()\n",
    "        self.data = data.reset_index(drop=True)\n",
    "        self.window_size = window_size\n",
    "        self.current_step = window_size\n",
    "        # Define action space: Discrete with three actions\n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(1,), dtype=np.float32)\n",
    "        self.position_size = 0  # From -1 (full short) to +1 (full long)\n",
    "        # Observation space: window of 2 features (Close_filtered and SMA)\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf,\n",
    "                                            shape=(window_size, 2), dtype=np.float32)\n",
    "        self.done = False\n",
    "        self.initial_balance = 10000\n",
    "        self.balance = self.initial_balance\n",
    "        self.position = 0    # +1 for long, -1 for short, 0 for no position\n",
    "        self.entry_price = 0\n",
    "        self.total_profit = 0\n",
    "        self.trades = []     # Log of trades\n",
    "        self.transaction_cost = transaction_cost  # Commission rate\n",
    "        self.slippage = slippage  # Maximum slippage factor\n",
    "        self.returns_window = []\n",
    "        self.risk_free_rate = 0.02/252  # Daily risk-free rate\n",
    "        \n",
    "    def _get_observation(self):\n",
    "        \"\"\"\n",
    "        Retrieve the current observation: a sliding window of normalized features.\n",
    "        \"\"\"\n",
    "        close_window = self.data['Close_filtered'].values[self.current_step - self.window_size:self.current_step]\n",
    "        sma_window = self.data['SMA'].values[self.current_step - self.window_size:self.current_step]\n",
    "\n",
    "        # Normalize each feature by its last value in the window (if nonzero)\n",
    "        norm_close = close_window / close_window[-1] if close_window[-1] != 0 else close_window\n",
    "        norm_sma = sma_window / sma_window[-1] if sma_window[-1] != 0 else sma_window\n",
    "\n",
    "        obs = np.column_stack((norm_close, norm_sma))\n",
    "        return obs.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Execute one time step within the environment.\n",
    "        \"\"\"\n",
    "        current_price = self.data['Close_filtered'].values[self.current_step - 1]\n",
    "        # Apply slippage to the next price\n",
    "        next_price_raw = (self.data['Close_filtered'].values[self.current_step]\n",
    "                          if self.current_step < len(self.data) else current_price)\n",
    "        slippage_factor = 1 + random.uniform(-self.slippage, self.slippage)\n",
    "        next_price = next_price_raw * slippage_factor\n",
    "        reward = 0\n",
    "\n",
    "        # Execute action: Buy, Sell, or Hold\n",
    "        if action == 1:  # Buy\n",
    "            if self.position == 0:\n",
    "                self.position = 1\n",
    "                self.entry_price = current_price\n",
    "                self.trades.append(('buy', self.current_step, current_price))\n",
    "        elif action == 2:  # Sell\n",
    "            if self.position == 0:\n",
    "                self.position = -1\n",
    "                self.entry_price = current_price\n",
    "                self.trades.append(('sell', self.current_step, current_price))\n",
    "\n",
    "        # Close position in the next step if a position is open\n",
    "        if self.position != 0:\n",
    "            if self.position == 1:\n",
    "                profit = next_price - self.entry_price  # Profit from long\n",
    "            else:\n",
    "                profit = self.entry_price - next_price  # Profit from short\n",
    "            # Apply a transaction cost (commission) on the exit trade\n",
    "            commission = self.transaction_cost * current_price\n",
    "            reward = profit - commission\n",
    "            self.balance += reward\n",
    "            self.total_profit += reward\n",
    "            self.position = 0  # Reset position\n",
    "\n",
    "        self.current_step += 1\n",
    "        if self.current_step >= len(self.data):\n",
    "            self.done = True\n",
    "\n",
    "        obs = self._get_observation() if not self.done else np.zeros(self.observation_space.shape, dtype=np.float32)\n",
    "        info = {'balance': self.balance, 'total_profit': self.total_profit}\n",
    "        # Calculate risk-adjusted return\n",
    "        daily_return = (self.balance/self.initial_balance) - 1\n",
    "        self.returns_window.append(daily_return)\n",
    "        if len(self.returns_window) > 30:\n",
    "            self.returns_window.pop(0)\n",
    "            \n",
    "        # Calculate Sharpe Ratio\n",
    "        excess_returns = [r - self.risk_free_rate for r in self.returns_window]\n",
    "        if len(excess_returns) > 1:\n",
    "            sharpe_ratio = np.mean(excess_returns) / np.std(excess_returns)\n",
    "            sharpe_ratio *= np.sqrt(252)  # Annualize\n",
    "        else:\n",
    "            sharpe_ratio = 0\n",
    "            \n",
    "        # Modify reward\n",
    "        reward = profit * (1 + sharpe_ratio)\n",
    "        \n",
    "        return obs, reward, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reset the environment state for a new episode.\n",
    "        \"\"\"\n",
    "        self.current_step = self.window_size\n",
    "        self.balance = self.initial_balance\n",
    "        self.position = 0\n",
    "        self.total_profit = 0\n",
    "        self.done = False\n",
    "        self.trades = []\n",
    "        return self._get_observation()\n",
    "\n",
    "    def render(self, mode='human', close=False):\n",
    "        \"\"\"\n",
    "        Render the environment state to the console.\n",
    "        \"\"\"\n",
    "        logger.info(\"Step: %d, Balance: %.2f, Total Profit: %.2f\", self.current_step, self.balance, self.total_profit)\n",
    "\n",
    "\n",
    "def train_rl_agent(env, hyperparams, timesteps=10000):\n",
    "    \"\"\"\n",
    "    Train the RL agent using PPO with the provided hyperparameters.\n",
    "    \"\"\"\n",
    "    model = PPO('MlpPolicy',\n",
    "                env,\n",
    "                verbose=0,\n",
    "                learning_rate=hyperparams.get('learning_rate', 0.0003),\n",
    "                gamma=hyperparams.get('gamma', 0.99),\n",
    "                clip_range=hyperparams.get('clip_range', 0.2))\n",
    "    model.learn(total_timesteps=timesteps)\n",
    "    return model\n",
    "\n",
    "\n",
    "def meta_learning_adaptation(model, env, adaptation_steps=10000, meta_lr=1e-4):\n",
    "    \"\"\"\n",
    "    Simulate meta-learning adaptation by fine-tuning the RL agent on new market data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Update the optimizer's learning rate\n",
    "    for param_group in model.policy.optimizer.param_groups:\n",
    "        param_group['lr'] = meta_lr\n",
    "\n",
    "    model.set_env(env)\n",
    "    logger.info(\"Starting meta-learning adaptation on new market data...\")\n",
    "    model.learn(total_timesteps=adaptation_steps, reset_num_timesteps=False)\n",
    "    logger.info(\"Meta-learning adaptation complete.\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def plot_results(info_history, title_suffix=\"\"):\n",
    "    \"\"\"\n",
    "    Plot the evolution of balance and total profit over time.\n",
    "    \"\"\"\n",
    "    balances = [info['balance'] for info in info_history]\n",
    "    profits = [info['total_profit'] for info in info_history]\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(balances, label='Balance', color='blue')\n",
    "    plt.title('Balance over Time ' + title_suffix)\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Balance')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(profits, label='Total Profit', color='orange')\n",
    "    plt.title('Total Profit over Time ' + title_suffix)\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Profit')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def eval_hyperparams(learning_rate, gamma, clip_range, episodes=1):\n",
    "    \"\"\"\n",
    "    Evaluate hyperparameters by training a temporary model and averaging reward over episodes.\n",
    "    \"\"\"\n",
    "    hyperparams = {\n",
    "        'learning_rate': float(learning_rate),\n",
    "        'gamma': float(gamma),\n",
    "        'clip_range': float(clip_range)\n",
    "    }\n",
    "    total_reward_across_episodes = 0\n",
    "    for _ in range(episodes):\n",
    "        temp_model = PPO('MlpPolicy', env, verbose=0,\n",
    "                         learning_rate=hyperparams['learning_rate'],\n",
    "                         gamma=hyperparams['gamma'],\n",
    "                         clip_range=hyperparams['clip_range'])\n",
    "        temp_model.learn(total_timesteps=2000)\n",
    "        obs = env.reset()\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            action, _ = temp_model.predict(obs)\n",
    "            obs, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "        total_reward_across_episodes += total_reward\n",
    "    avg_reward = total_reward_across_episodes / episodes\n",
    "    logger.info(\"Evaluated hyperparams: %s, Avg Reward: %.2f\", hyperparams, avg_reward)\n",
    "    return avg_reward\n",
    "\n",
    "\n",
    "def eval_individual(individual, episodes=1):\n",
    "    \"\"\"\n",
    "    Evaluate an individual (set of hyperparameters) using Genetic Algorithm.\n",
    "    \"\"\"\n",
    "    lr, gamma, clip_range = individual\n",
    "    lr = max(lr, 1e-6)\n",
    "    individual[0] = lr  # ensure minimum learning rate\n",
    "    total_reward_across_episodes = 0\n",
    "    for _ in range(episodes):\n",
    "        temp_model = PPO('MlpPolicy', env, verbose=0,\n",
    "                         learning_rate=lr,\n",
    "                         gamma=gamma,\n",
    "                         clip_range=clip_range)\n",
    "        temp_model.learn(total_timesteps=2000)\n",
    "        obs = env.reset()\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            action, _ = temp_model.predict(obs)\n",
    "            obs, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "        total_reward_across_episodes += total_reward\n",
    "    avg_reward = total_reward_across_episodes / episodes\n",
    "    return (avg_reward,)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # ---------------------------\n",
    "    # 1. Data Loading and Preprocessing\n",
    "    # ---------------------------\n",
    "    data = load_data()\n",
    "    logger.info(\"Data loaded with shape: %s\", data.shape)\n",
    "    data = noise_filtering(data, plot=False)  # Set plot=True to visualize filtering\n",
    "    logger.info(\"Data after noise filtering, sample:\\n%s\", data.head())\n",
    "\n",
    "    # ---------------------------\n",
    "    # 2. Environment Initialization\n",
    "    # ---------------------------\n",
    "    global env\n",
    "    env = TradingEnv(data, window_size=20, transaction_cost=0.001, slippage=0.001)\n",
    "    logger.info(\"Trading environment initialized.\")\n",
    "\n",
    "    # ---------------------------\n",
    "    # 3. Hyperparameter Tuning (Bayesian Optimization)\n",
    "    # ---------------------------\n",
    "    logger.info(\"Tuning hyperparameters using Bayesian Optimization...\")\n",
    "    optimizer = BayesianOptimization(\n",
    "    f=lambda learning_rate, gamma, clip_range: eval_hyperparams(learning_rate, gamma, clip_range, episodes=1),\n",
    "    pbounds={'learning_rate': (1e-5, 1e-3),\n",
    "             'gamma': (0.90, 0.999),\n",
    "             'clip_range': (0.1, 0.3)},\n",
    "    random_state=50,\n",
    "    )\n",
    "    optimizer.maximize(init_points=5, n_iter=10)\n",
    "    best_params_bo = optimizer.max['params']\n",
    "    logger.info(\"Best Hyperparameters (Bayesian Optimization): %s\", best_params_bo)\n",
    "\n",
    "\n",
    "    # ---------------------------\n",
    "    # 4. Hyperparameter Tuning (Genetic Algorithm)\n",
    "    # ---------------------------\n",
    "    logger.info(\"Tuning hyperparameters using Genetic Algorithm...\")\n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "    def init_individual():\n",
    "        return [np.random.uniform(1e-6, 1e-3),  # Learning rate\n",
    "                np.random.uniform(0.90, 0.999),  # Gamma\n",
    "                np.random.uniform(0.1, 0.3)]     # Clip range\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"individual\", tools.initIterate, creator.Individual, init_individual)\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "    toolbox.register(\"evaluate\", lambda ind: eval_individual(ind, episodes=1))\n",
    "    toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
    "    toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=0.1, indpb=0.2)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "    population = toolbox.population(n=10)\n",
    "    algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2, ngen=5, verbose=True)\n",
    "    best_ind = tools.selBest(population, k=1)[0]\n",
    "    best_params_ga = {'learning_rate': best_ind[0], 'gamma': best_ind[1], 'clip_range': best_ind[2]}\n",
    "    logger.info(\"Best Hyperparameters (Genetic Algorithm): %s\", best_params_ga)\n",
    "\n",
    "    # For training, select one set (here, we choose Bayesian's result)\n",
    "    best_hyperparams = best_params_bo\n",
    "\n",
    "    # ---------------------------\n",
    "    # 5. RL Agent Training\n",
    "    # ---------------------------\n",
    "    logger.info(\"Training RL agent with tuned hyperparameters...\")\n",
    "    trained_model = train_rl_agent(env, best_hyperparams, timesteps=5000)\n",
    "\n",
    "    # Evaluate the trained model\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    info_history = []\n",
    "    while not done:\n",
    "        action, _ = trained_model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        info_history.append(info)\n",
    "    plot_results(info_history, title_suffix=\"(Pre-Adaptation)\")\n",
    "\n",
    "    # ---------------------------\n",
    "    # 6. Meta-Learning Adaptation\n",
    "    # ---------------------------\n",
    "    logger.info(\"Performing meta-learning adaptation on new market conditions...\")\n",
    "    # Simulate new market conditions by shuffling the data\n",
    "    data_new = data.sample(frac=1).reset_index(drop=True)\n",
    "    env_new = TradingEnv(data_new, window_size=20, transaction_cost=0.001, slippage=0.001)\n",
    "    adapted_model = meta_learning_adaptation(trained_model, env_new, adaptation_steps=2000, meta_lr=1e-4)\n",
    "\n",
    "    # Evaluate the adapted model\n",
    "    obs = env_new.reset()\n",
    "    done = False\n",
    "    info_history_new = []\n",
    "    while not done:\n",
    "        action, _ = adapted_model.predict(obs)\n",
    "        obs, reward, done, info = env_new.step(action)\n",
    "        info_history_new.append(info)\n",
    "    plot_results(info_history_new, title_suffix=\"(Post-Adaptation)\")\n",
    "\n",
    "    # ---------------------------\n",
    "    # 7. Save the Final Model\n",
    "    # ---------------------------\n",
    "    adapted_model.save(\"adaptive_trading_bot2\")\n",
    "    logger.info(\"Model saved as 'adaptive_trading_bot'\")\n",
    "\n",
    "    # ---------------------------\n",
    "    # 8. Using the Trained Model on a New Dataset\n",
    "    # ---------------------------\n",
    "    logger.info(\"Loading and using the saved model on a new dataset...\")\n",
    "    # Example: Load a new dataset (here, using a different cache file for demonstration)\n",
    "    new_data = load_data(cache_file=\"binance_data_new.csv\")\n",
    "    new_data = noise_filtering(new_data, plot=False)\n",
    "    new_env = TradingEnv(new_data, window_size=20, transaction_cost=0.001, slippage=0.001)\n",
    "\n",
    "    # Load the saved model and set its environment\n",
    "    model_loaded = PPO.load(\"adaptive_trading_bot2\")\n",
    "    model_loaded.set_env(new_env)\n",
    "\n",
    "    obs = new_env.reset()\n",
    "    done = False\n",
    "    info_history_new_dataset = []\n",
    "    while not done:\n",
    "        action, _ = model_loaded.predict(obs)\n",
    "        obs, reward, done, info = new_env.step(action)\n",
    "        info_history_new_dataset.append(info)\n",
    "    plot_results(info_history_new_dataset, title_suffix=\"(New Dataset)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
