{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-02-11 02:22:00</th>\n",
       "      <td>97660.46</td>\n",
       "      <td>97729.33</td>\n",
       "      <td>97660.46</td>\n",
       "      <td>97705.79</td>\n",
       "      <td>13.41279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-11 02:23:00</th>\n",
       "      <td>97705.78</td>\n",
       "      <td>97705.79</td>\n",
       "      <td>97629.38</td>\n",
       "      <td>97653.97</td>\n",
       "      <td>7.93944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-11 02:24:00</th>\n",
       "      <td>97653.96</td>\n",
       "      <td>97711.15</td>\n",
       "      <td>97619.43</td>\n",
       "      <td>97711.14</td>\n",
       "      <td>16.62807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-11 02:25:00</th>\n",
       "      <td>97711.15</td>\n",
       "      <td>97790.55</td>\n",
       "      <td>97711.14</td>\n",
       "      <td>97756.24</td>\n",
       "      <td>12.37841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-11 02:26:00</th>\n",
       "      <td>97756.23</td>\n",
       "      <td>97756.23</td>\n",
       "      <td>97696.98</td>\n",
       "      <td>97696.99</td>\n",
       "      <td>9.74859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-11 18:57:00</th>\n",
       "      <td>95510.38</td>\n",
       "      <td>95533.46</td>\n",
       "      <td>95509.97</td>\n",
       "      <td>95509.97</td>\n",
       "      <td>9.46631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-11 18:58:00</th>\n",
       "      <td>95509.97</td>\n",
       "      <td>95523.95</td>\n",
       "      <td>95500.27</td>\n",
       "      <td>95523.95</td>\n",
       "      <td>8.00227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-11 18:59:00</th>\n",
       "      <td>95523.94</td>\n",
       "      <td>95523.95</td>\n",
       "      <td>95423.83</td>\n",
       "      <td>95469.28</td>\n",
       "      <td>11.55498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-11 19:00:00</th>\n",
       "      <td>95469.28</td>\n",
       "      <td>95558.00</td>\n",
       "      <td>95456.26</td>\n",
       "      <td>95533.47</td>\n",
       "      <td>26.43093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-11 19:01:00</th>\n",
       "      <td>95533.47</td>\n",
       "      <td>95533.48</td>\n",
       "      <td>95525.64</td>\n",
       "      <td>95528.47</td>\n",
       "      <td>0.71894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         open      high       low     close    volume\n",
       "timestamp                                                            \n",
       "2025-02-11 02:22:00  97660.46  97729.33  97660.46  97705.79  13.41279\n",
       "2025-02-11 02:23:00  97705.78  97705.79  97629.38  97653.97   7.93944\n",
       "2025-02-11 02:24:00  97653.96  97711.15  97619.43  97711.14  16.62807\n",
       "2025-02-11 02:25:00  97711.15  97790.55  97711.14  97756.24  12.37841\n",
       "2025-02-11 02:26:00  97756.23  97756.23  97696.98  97696.99   9.74859\n",
       "...                       ...       ...       ...       ...       ...\n",
       "2025-02-11 18:57:00  95510.38  95533.46  95509.97  95509.97   9.46631\n",
       "2025-02-11 18:58:00  95509.97  95523.95  95500.27  95523.95   8.00227\n",
       "2025-02-11 18:59:00  95523.94  95523.95  95423.83  95469.28  11.55498\n",
       "2025-02-11 19:00:00  95469.28  95558.00  95456.26  95533.47  26.43093\n",
       "2025-02-11 19:01:00  95533.47  95533.48  95525.64  95528.47   0.71894\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ccxt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "import talib\n",
    "import requests\n",
    "from gym import spaces, Env\n",
    "\n",
    "# Configuration\n",
    "INITIAL_BALANCE = 10.0\n",
    "TRADING_FEE = 0.10  # 10%\n",
    "LOOKBACK_WINDOW = 60  # 60 periods (5 hours)\n",
    "INDICATOR_WINDOW = 14\n",
    "url = \"https://api.binance.com/api/v3/klines\"\n",
    "params = {\n",
    "    'symbol': 'BTCUSDT',  # The trading pair\n",
    "    'interval': '1m',     # 1-minute candlesticks\n",
    "    'limit': 1000        # Number of data points to fetch\n",
    "}\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "data = response.json()\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = pd.DataFrame(\n",
    "        data,\n",
    "        columns=['timestamp', 'open', 'high', 'low', 'close', 'volume', \n",
    "                    'close_time', 'quote_asset_volume', 'number_of_trades', \n",
    "                    'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore']\n",
    "    )\n",
    "    data = data[['timestamp', 'open', 'high', 'low', 'close', 'volume']]\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'], unit='ms')\n",
    "    data.set_index('timestamp', inplace=True)\n",
    "    data = data.astype(float)\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}, {response.text}\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         open      high       low     close    volume  \\\n",
      "timestamp                                                               \n",
      "2025-02-11 18:31:00  95649.49  95757.80  95649.48  95738.91  12.72812   \n",
      "2025-02-11 18:32:00  95738.92  95784.58  95738.92  95784.58  13.47782   \n",
      "2025-02-11 18:33:00  95784.57  95801.94  95755.15  95801.94   6.39397   \n",
      "2025-02-11 18:34:00  95801.93  95833.50  95780.37  95833.50   9.65216   \n",
      "2025-02-11 18:35:00  95833.50  95846.13  95775.83  95846.13  12.87486   \n",
      "\n",
      "                         SMA_50        EMA_20     ADX_14  Tenkan-sen  \\\n",
      "timestamp                                                              \n",
      "2025-02-11 18:31:00  95936.9362  95755.858726  52.765134   95682.900   \n",
      "2025-02-11 18:32:00  95929.3720  95758.594085  52.383253   95696.290   \n",
      "2025-02-11 18:33:00  95923.1378  95762.722267  52.419877   95711.825   \n",
      "2025-02-11 18:34:00  95917.7674  95769.463004  53.120539   95727.605   \n",
      "2025-02-11 18:35:00  95910.7702  95776.764623  51.995673   95733.920   \n",
      "\n",
      "                     Kijun-sen  ...  MACD_Signal     Stoch_K    Stoch_D  \\\n",
      "timestamp                       ...                                       \n",
      "2025-02-11 18:31:00  95801.950  ...   -87.909697   48.306273  29.150062   \n",
      "2025-02-11 18:32:00  95779.000  ...   -84.381695   65.158672  42.923739   \n",
      "2025-02-11 18:33:00  95776.225  ...   -79.208448   81.603972  65.022972   \n",
      "2025-02-11 18:34:00  95776.225  ...   -72.591130  100.000000  82.254215   \n",
      "2025-02-11 18:35:00  95776.225  ...   -65.048633  100.000000  93.867991   \n",
      "\n",
      "                            OBV          VWAP      BB_Upper      BB_Lower  \\\n",
      "timestamp                                                                   \n",
      "2025-02-11 18:31:00 -1061.61400  97315.877829  95963.982792  95558.748208   \n",
      "2025-02-11 18:32:00 -1048.13618  97314.186522  95945.642274  95564.496726   \n",
      "2025-02-11 18:33:00 -1041.74221  97313.394552  95928.432283  95571.318717   \n",
      "2025-02-11 18:34:00 -1032.09005  97312.225516  95912.032606  95579.669394   \n",
      "2025-02-11 18:35:00 -1019.21519  97310.682325  95914.452756  95578.700244   \n",
      "\n",
      "                        ATR_14  Keltner_Upper  Keltner_Lower  \n",
      "timestamp                                                     \n",
      "2025-02-11 18:31:00  63.081429   95877.369726   95634.347726  \n",
      "2025-02-11 18:32:00  61.302857   95879.356085   95637.832085  \n",
      "2025-02-11 18:33:00  60.357857   95884.299267   95641.145267  \n",
      "2025-02-11 18:34:00  62.182857   95891.899004   95647.027004  \n",
      "2025-02-11 18:35:00  61.101429   95895.799623   95657.729623  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define Indicator Functions\n",
    "def SMA(data, period=14, column='close'):\n",
    "    return data[column].rolling(window=period).mean()\n",
    "\n",
    "def EMA(data, period=14, column='close'):\n",
    "    return data[column].ewm(span=period, adjust=False).mean()\n",
    "\n",
    "def ADX(data, period=14):\n",
    "    high, low, close = data['high'], data['low'], data['close']\n",
    "    plus_dm = high.diff().clip(lower=0)\n",
    "    minus_dm = -low.diff().clip(upper=0)\n",
    "    tr = pd.concat([high - low, abs(high - close.shift(1)), abs(low - close.shift(1))], axis=1).max(axis=1)\n",
    "    atr = tr.rolling(window=period).mean()\n",
    "    plus_di = 100 * (plus_dm.ewm(span=period, adjust=False).mean() / atr)\n",
    "    minus_di = abs(100 * (minus_dm.ewm(span=period, adjust=False).mean() / atr))\n",
    "    dx = (abs(plus_di - minus_di) / (plus_di + minus_di)) * 100\n",
    "    return dx.rolling(window=period).mean().dropna()\n",
    "\n",
    "def calculate_di(data, period=14):\n",
    "    high = data['high']\n",
    "    low = data['low']\n",
    "    close = data['close']\n",
    "\n",
    "    # Calculate the Directional Movement (DM)\n",
    "    plus_dm = high.diff().clip(lower=0)\n",
    "    minus_dm = -low.diff().clip(upper=0)\n",
    "\n",
    "    # True Range (TR)\n",
    "    tr = pd.concat([high - low, abs(high - close.shift(1)), abs(low - close.shift(1))], axis=1).max(axis=1)\n",
    "\n",
    "    # Smooth the DM and TR over the period\n",
    "    smoothed_plus_dm = plus_dm.rolling(window=period).sum()\n",
    "    smoothed_minus_dm = minus_dm.rolling(window=period).sum()\n",
    "    smoothed_tr = tr.rolling(window=period).sum()\n",
    "\n",
    "    # Calculate +DI and -DI\n",
    "    data['+DI'] = (smoothed_plus_dm / smoothed_tr) * 100\n",
    "    data['-DI'] = (smoothed_minus_dm / smoothed_tr) * 100\n",
    "    \n",
    "    return data[['+DI', '-DI']].dropna()\n",
    "\n",
    "def Ichimoku(data):\n",
    "    data = data.copy()\n",
    "    high, low = data['high'], data['low']\n",
    "\n",
    "    data['Tenkan-sen'] = (high.rolling(window=9).max() + low.rolling(window=9).min()) / 2\n",
    "    data['Kijun-sen'] = (high.rolling(window=26).max() + low.rolling(window=26).min()) / 2\n",
    "    data['Senkou Span A'] = ((data['Tenkan-sen'] + data['Kijun-sen']) / 2).shift(26)\n",
    "    data['Senkou Span B'] = ((high.rolling(window=52).max() + low.rolling(window=52).min()) / 2).shift(26)\n",
    "    data['Chikou Span'] = data['close'].shift(-26)\n",
    "\n",
    "    # Ensure all missing values are handled properly\n",
    "    return data[['Tenkan-sen', 'Kijun-sen', 'Senkou Span A', 'Senkou Span B', 'Chikou Span']].dropna()\n",
    "\n",
    "\n",
    "def RSI(data, period=14, column='close'):\n",
    "    delta = data[column].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
    "    rs = gain / loss\n",
    "    return (100 - (100 / (1 + rs))).dropna()\n",
    "\n",
    "def MACD(data, short_period=12, long_period=26, signal_period=9):\n",
    "    short_ema = EMA(data, short_period)\n",
    "    long_ema = EMA(data, long_period)\n",
    "    macd_line = short_ema - long_ema\n",
    "    signal_line = macd_line.ewm(span=signal_period, adjust=False).mean()\n",
    "    return macd_line.dropna(), signal_line.dropna()\n",
    "\n",
    "def Stochastic_Oscillator(data, period=14):\n",
    "    high, low, close = data['high'], data['low'], data['close']\n",
    "    lowest_low = low.rolling(window=period).min()\n",
    "    highest_high = high.rolling(window=period).max()\n",
    "    k = 100 * ((close - lowest_low) / (highest_high - lowest_low))\n",
    "    d = k.rolling(window=3).mean()\n",
    "    return k.dropna(), d.dropna()\n",
    "\n",
    "def OBV(data):\n",
    "    obv = (data['close'].diff().fillna(0) > 0) * data['volume'] - (data['close'].diff().fillna(0) < 0) * data['volume']\n",
    "    return obv.cumsum().dropna()\n",
    "\n",
    "def VWAP(data):\n",
    "    return ((data['close'] * data['volume']).cumsum() / data['volume'].cumsum()).dropna()\n",
    "\n",
    "def Bollinger_Bands(data, period=20):\n",
    "    sma = SMA(data, period)\n",
    "    std = data['close'].rolling(window=period).std()\n",
    "    upper_band = sma + (2 * std)\n",
    "    lower_band = sma - (2 * std)\n",
    "    return upper_band.dropna(), lower_band.dropna()\n",
    "\n",
    "def ATR(data, period=14):\n",
    "    high, low, close = data['high'], data['low'], data['close']\n",
    "    tr = pd.concat([\n",
    "        high - low, \n",
    "        abs(high - close.shift()), \n",
    "        abs(low - close.shift())\n",
    "    ], axis=1).max(axis=1)\n",
    "    return tr.rolling(window=period).mean().dropna()\n",
    "\n",
    "def Keltner_Channel(data, period=20):\n",
    "    ema = EMA(data, period)\n",
    "    atr = ATR(data, period)\n",
    "    upper_band = ema + (2 * atr)\n",
    "    lower_band = ema - (2 * atr)\n",
    "    return upper_band.dropna(), lower_band.dropna()\n",
    "# Ensure 'data' is a DataFrame\n",
    "if isinstance(data, list):\n",
    "    data = pd.DataFrame(data)\n",
    "\n",
    "# Calculate Indicators and Add to DataFrame\n",
    "data['SMA_50'] = SMA(data, 50)\n",
    "data['EMA_20'] = EMA(data, 20)\n",
    "data['ADX_14'] = ADX(data, 14)\n",
    "ichimoku = Ichimoku(data)\n",
    "data = pd.concat([data, ichimoku], axis=1)\n",
    "data[['+DI', '-DI']] = calculate_di(data, 14)\n",
    "data['RSI_14'] = RSI(data, 14)\n",
    "data['MACD'], data['MACD_Signal'] = MACD(data)\n",
    "data['Stoch_K'], data['Stoch_D'] = Stochastic_Oscillator(data)\n",
    "data['OBV'] = OBV(data)\n",
    "data['VWAP'] = VWAP(data)\n",
    "data['BB_Upper'], data['BB_Lower'] = Bollinger_Bands(data)\n",
    "data['ATR_14'] = ATR(data, 14)\n",
    "data['Keltner_Upper'], data['Keltner_Lower'] = Keltner_Channel(data)\n",
    "\n",
    "# Drop NaN values across all calculated indicators\n",
    "data = data.dropna()\n",
    "\n",
    "# Print the last few rows of the DataFrame\n",
    "print(data.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Trading Indicators Guide</h1>\n",
    "\n",
    "<h2>1. Trend Indicators ðŸ“ˆ (Detect Market Direction)</h2>\n",
    "\n",
    "<h3>(a) Simple Moving Average (SMA) & Exponential Moving Average (EMA)</h3>\n",
    "<p><strong>âœ… What It Detects:</strong></p>\n",
    "<ul>\n",
    "    <li>SMA: Long-term trend direction.</li>\n",
    "    <li>EMA: Short-term trend with more weight on recent prices.</li>\n",
    "</ul>\n",
    "<p><strong>ðŸ“Š How to Interpret Results:</strong></p>\n",
    "<ul>\n",
    "    <li>Price above SMA/EMA â†’ Uptrend (Bullish signal)</li>\n",
    "    <li>Price below SMA/EMA â†’ Downtrend (Bearish signal)</li>\n",
    "    <li>Golden Cross (50 EMA > 200 EMA) â†’ Strong Bullish</li>\n",
    "    <li>Death Cross (50 EMA < 200 EMA) â†’ Strong Bearish</li>\n",
    "</ul>\n",
    "\n",
    "<h3>(b) Average Directional Index (ADX)</h3>\n",
    "<p><strong>âœ… What It Detects:</strong></p>\n",
    "<ul>\n",
    "    <li>Strength of a trend (not direction).</li>\n",
    "</ul>\n",
    "<p><strong>ðŸ“Š How to Interpret Results:</strong></p>\n",
    "<ul>\n",
    "    <li>ADX > 25 â†’ Strong trend (either bullish or bearish).</li>\n",
    "    <li>ADX < 20 â†’ Weak trend (sideways movement).</li>\n",
    "    <li>Increasing ADX â†’ Trend is gaining strength.</li>\n",
    "    <li>Decreasing ADX â†’ Trend is weakening.</li>\n",
    "</ul>\n",
    "\n",
    "<h3>(c) Ichimoku Cloud</h3>\n",
    "<p><strong>âœ… What It Detects:</strong></p>\n",
    "<ul>\n",
    "    <li>Trend direction, support/resistance, and momentum.</li>\n",
    "</ul>\n",
    "<p><strong>ðŸ“Š How to Interpret Results:</strong></p>\n",
    "<ul>\n",
    "    <li>Price above the cloud â†’ Bullish trend.</li>\n",
    "    <li>Price below the cloud â†’ Bearish trend.</li>\n",
    "    <li>Price inside the cloud â†’ Consolidation/Uncertainty.</li>\n",
    "</ul>\n",
    "\n",
    "<h2>2. Momentum Indicators ðŸš€ (Measure Strength of Price Movement)</h2>\n",
    "\n",
    "<h3>(a) Relative Strength Index (RSI)</h3>\n",
    "<p><strong>âœ… What It Detects:</strong></p>\n",
    "<ul>\n",
    "    <li>Overbought and oversold conditions (potential reversal points).</li>\n",
    "</ul>\n",
    "<p><strong>ðŸ“Š How to Interpret Results:</strong></p>\n",
    "<ul>\n",
    "    <li>RSI > 70 â†’ Overbought (Sell signal).</li>\n",
    "    <li>RSI < 30 â†’ Oversold (Buy signal).</li>\n",
    "    <li>Divergence (Price rises but RSI falls) â†’ Weakening trend, possible reversal.</li>\n",
    "</ul>\n",
    "\n",
    "<h3>(b) Moving Average Convergence Divergence (MACD)</h3>\n",
    "<p><strong>âœ… What It Detects:</strong></p>\n",
    "<ul>\n",
    "    <li>Trend direction, momentum, and reversals.</li>\n",
    "</ul>\n",
    "<p><strong>ðŸ“Š How to Interpret Results:</strong></p>\n",
    "<ul>\n",
    "    <li>MACD line crosses above Signal line â†’ Bullish crossover (Buy).</li>\n",
    "    <li>MACD line crosses below Signal line â†’ Bearish crossover (Sell).</li>\n",
    "    <li>MACD Divergence â†’ Price making higher highs while MACD falls â†’ Possible trend reversal.</li>\n",
    "</ul>\n",
    "\n",
    "<h3>(c) Stochastic Oscillator</h3>\n",
    "<p><strong>âœ… What It Detects:</strong></p>\n",
    "<ul>\n",
    "    <li>Momentum shifts and overbought/oversold conditions.</li>\n",
    "</ul>\n",
    "<p><strong>ðŸ“Š How to Interpret Results:</strong></p>\n",
    "<ul>\n",
    "    <li>%K > 80 â†’ Overbought (Sell signal).</li>\n",
    "    <li>%K < 20 â†’ Oversold (Buy signal).</li>\n",
    "    <li>%K crossing %D from below â†’ Bullish reversal.</li>\n",
    "    <li>%K crossing %D from above â†’ Bearish reversal.</li>\n",
    "</ul>\n",
    "\n",
    "<h2>3. Volume Indicators ðŸ“Š (Confirm Market Strength)</h2>\n",
    "\n",
    "<h3>(a) On-Balance Volume (OBV)</h3>\n",
    "<p><strong>âœ… What It Detects:</strong></p>\n",
    "<ul>\n",
    "    <li>Buying vs. selling pressure.</li>\n",
    "</ul>\n",
    "<p><strong>ðŸ“Š How to Interpret Results:</strong></p>\n",
    "<ul>\n",
    "    <li>Rising OBV â†’ Buying pressure (Bullish).</li>\n",
    "    <li>Falling OBV â†’ Selling pressure (Bearish).</li>\n",
    "    <li>Divergence (Price rising, OBV falling) â†’ Weak uptrend, possible reversal.</li>\n",
    "</ul>\n",
    "\n",
    "<h3>(b) Volume Weighted Average Price (VWAP)</h3>\n",
    "<p><strong>âœ… What It Detects:</strong></p>\n",
    "<ul>\n",
    "    <li>Trend strength based on volume-weighted prices.</li>\n",
    "</ul>\n",
    "<p><strong>ðŸ“Š How to Interpret Results:</strong></p>\n",
    "<ul>\n",
    "    <li>Price above VWAP â†’ Strong bullish trend.</li>\n",
    "    <li>Price below VWAP â†’ Strong bearish trend.</li>\n",
    "    <li>VWAP flat â†’ Market is ranging (no clear trend).</li>\n",
    "</ul>\n",
    "\n",
    "<h2>4. Volatility Indicators âš¡ (Measure Market Risk & Big Moves)</h2>\n",
    "\n",
    "<h3>(a) Bollinger Bands (BB)</h3>\n",
    "<p><strong>âœ… What It Detects:</strong></p>\n",
    "<ul>\n",
    "    <li>Volatility and potential breakouts.</li>\n",
    "</ul>\n",
    "<p><strong>ðŸ“Š How to Interpret Results:</strong></p>\n",
    "<ul>\n",
    "    <li>Price touches upper band â†’ Overbought (Sell signal).</li>\n",
    "    <li>Price touches lower band â†’ Oversold (Buy signal).</li>\n",
    "    <li>Bands expand â†’ Increased volatility (Big move expected).</li>\n",
    "    <li>Bands contract â†’ Low volatility (Possible breakout).</li>\n",
    "</ul>\n",
    "\n",
    "<h3>(b) Average True Range (ATR)</h3>\n",
    "<p><strong>âœ… What It Detects:</strong></p>\n",
    "<ul>\n",
    "    <li>Market volatility (size of price movements).</li>\n",
    "</ul>\n",
    "<p><strong>ðŸ“Š How to Interpret Results:</strong></p>\n",
    "<ul>\n",
    "    <li>High ATR â†’ High volatility (Big price swings).</li>\n",
    "    <li>Low ATR â†’ Low volatility (Stable price movement).</li>\n",
    "    <li>Rising ATR â†’ Market getting volatile (Breakout possible).</li>\n",
    "</ul>\n",
    "\n",
    "<h3>(c) Keltner Channel</h3>\n",
    "<p><strong>âœ… What It Detects:</strong></p>\n",
    "<ul>\n",
    "    <li>Trend direction and volatility.</li>\n",
    "</ul>\n",
    "<p><strong>ðŸ“Š How to Interpret Results:</strong></p>\n",
    "<ul>\n",
    "    <li>Price above upper band â†’ Strong bullish move.</li>\n",
    "    <li>Price below lower band â†’ Strong bearish move.</li>\n",
    "    <li>Price inside the bands â†’ Normal market behavior.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strategy Type >\tBest Indicator Combinations <br>\n",
    "Trend-Following >\tEMA + ADX + Ichimoku Cloud<br>\n",
    "Momentum-Based >\tRSI + MACD + Stochastic Oscillator<br>\n",
    "Breakout Trading >\tBollinger Bands + ATR + OBV<br>\n",
    "Mean Reversion >\tRSI + Bollinger Bands + VWAP<br>\n",
    "Scalping/Day Trading >\tVWAP + Stochastic RSI + Volume<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMA bullish\n",
      "EMA bullish\n",
      "ADX neutral\n",
      "Ichimoku bullish\n",
      "RSI bullish\n",
      "MACD bullish\n",
      "Stochastic Oscillator bearish\n",
      "OBV bearish\n",
      "VWAP bullish\n",
      "Bollinger Bands neutral\n",
      "ATR bearish\n",
      "Keltner Channel neutral\n",
      "6 3 3\n",
      "Final Prediction: bullish\n"
     ]
    }
   ],
   "source": [
    "def get_signal(data):\n",
    "    signals = []\n",
    "    indicators = ['SMA','EMA','ADX','Ichimoku','RSI','MACD','Stochastic Oscillator','OBV','VWAP','Bollinger Bands','ATR','Keltner Channel']\n",
    "    # SMA\n",
    "    if data['close'].iloc[-1] > data['SMA_50'].iloc[-1]:\n",
    "        signals.append('bullish')\n",
    "    elif data['close'].iloc[-1] < data['SMA_50'].iloc[-1]:\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "\n",
    "    # EMA\n",
    "    if data['close'].iloc[-1] > data['EMA_20'].iloc[-1]:\n",
    "        signals.append('bullish')\n",
    "    elif data['close'].iloc[-1] < data['EMA_20'].iloc[-1]:\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "\n",
    "    # ADX\n",
    "    if data['ADX_14'].iloc[-1] > 25 and data['+DI'].iloc[-1] > data['-DI'].iloc[-1]:\n",
    "        signals.append('bullish')\n",
    "    elif data['ADX_14'].iloc[-1] > 25 and data['+DI'].iloc[-1] < data['-DI'].iloc[-1]:\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "\n",
    "    # Ichimoku\n",
    "    if data['close'].iloc[-1] > data['Senkou Span A'].iloc[-1] and data['Tenkan-sen'].iloc[-1] > data['Kijun-sen'].iloc[-1]:\n",
    "        signals.append('bullish')\n",
    "    elif data['close'].iloc[-1] < data['Senkou Span A'].iloc[-1] and data['Tenkan-sen'].iloc[-1] < data['Kijun-sen'].iloc[-1]:\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "\n",
    "    # RSI\n",
    "    if data['RSI_14'].iloc[-1] < 30 or data['RSI_14'].iloc[-1] > 50:\n",
    "        signals.append('bullish')\n",
    "    elif data['RSI_14'].iloc[-1] > 30 or data['RSI_14'].iloc[-1] < 50:\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "\n",
    "    # MACD\n",
    "    if data['MACD'].iloc[-1] > data['MACD_Signal'].iloc[-1]:\n",
    "        signals.append('bullish')\n",
    "    elif data['MACD'].iloc[-1] < data['MACD_Signal'].iloc[-1]:\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "\n",
    "    # Stochastic Oscillator\n",
    "    if data['Stoch_K'].iloc[-1] > data['Stoch_D'].iloc[-1] and data['Stoch_K'].iloc[-1] < 20:\n",
    "        signals.append('bullish')\n",
    "    elif data['Stoch_K'].iloc[-1] < data['Stoch_D'].iloc[-1] and data['Stoch_K'].iloc[-1] > 20:\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "\n",
    "    # OBV\n",
    "    if data['OBV'].iloc[-1] > data['OBV'].iloc[-2]:  # OBV rising\n",
    "        signals.append('bullish')\n",
    "    elif data['OBV'].iloc[-1] < data['OBV'].iloc[-2]:\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "\n",
    "    # VWAP\n",
    "    if data['close'].iloc[-1] > data['VWAP'].iloc[-1]:\n",
    "        signals.append('bullish')\n",
    "    elif data['close'].iloc[-1] < data['VWAP'].iloc[-1]:\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "\n",
    "    # Bollinger Bands\n",
    "    if data['close'].iloc[-1] < data['BB_Lower'].iloc[-1]:  # Touching lower band\n",
    "        signals.append('bullish')\n",
    "    elif data['close'].iloc[-1] > data['BB_Upper'].iloc[-1]:  # Touching upper band\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "\n",
    "    # ATR (Volatility Expansion)\n",
    "    if data['ATR_14'].iloc[-1] > data['ATR_14'].iloc[-2]:  # ATR increasing\n",
    "        signals.append('bullish')\n",
    "    elif data['ATR_14'].iloc[-1] < data['ATR_14'].iloc[-2]:\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "\n",
    "    # Keltner Channel\n",
    "    if data['close'].iloc[-1] > data['Keltner_Upper'].iloc[-1]:\n",
    "        signals.append('bullish')\n",
    "    elif data['close'].iloc[-1] < data['Keltner_Lower'].iloc[-1]:\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "        \n",
    "\n",
    "    # Count bullish and bearish signals\n",
    "    bullish_count = signals.count('bullish')\n",
    "    bearish_count = signals.count('bearish')\n",
    "    for i in range(len(indicators)):\n",
    "        print(indicators[i]+' '+signals[i])\n",
    "    print(bullish_count,bearish_count,len(signals)-bullish_count-bearish_count)\n",
    "    # Final prediction\n",
    "    if bullish_count > bearish_count:\n",
    "        return 'bullish'\n",
    "    elif bearish_count > bullish_count:\n",
    "        return 'bearish'\n",
    "    else:\n",
    "        return 'neutral'  # When there's a tie or no clear trend\n",
    "    \n",
    "\n",
    "# Example: Get the final signal for the most recent data\n",
    "signal = get_signal(data)\n",
    "print(f\"Final Prediction: {signal}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TradingModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_layers=3, hidden_units=64):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for _ in range(num_layers):\n",
    "            layers.append(nn.Linear(input_dim, hidden_units))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = hidden_units\n",
    "        layers.append(nn.Linear(hidden_units, 1))  # Predict return\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maml_train(model, tasks, inner_lr, inner_steps, outer_lr, epochs):\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=outer_lr)\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for task in tasks:\n",
    "            # Clone model for inner loop\n",
    "            fast_weights = dict(model.named_parameters())\n",
    "            \n",
    "            # Inner loop adaptation\n",
    "            for _ in range(inner_steps):\n",
    "                loss = compute_loss(task['support'], model, fast_weights)\n",
    "                grads = torch.autograd.grad(loss, fast_weights.values())\n",
    "                fast_weights = {name: param - inner_lr * grad \n",
    "                               for (name, param), grad in zip(fast_weights.items(), grads)}\n",
    "            \n",
    "            # Compute query loss and backprop\n",
    "            query_loss = compute_loss(task['query'], model, fast_weights)\n",
    "            total_loss += query_loss\n",
    "            query_loss.backward()\n",
    "        \n",
    "        # Outer optimization step\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-02-11 13:07:21,511] A new study created in memory with name: no-name-6ff007ee-e3a2-4df7-b834-fef408445eb8\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_16156\\1450247049.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'inner_lr': trial.suggest_loguniform('inner_lr', 1e-5, 1e-2),\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_16156\\1450247049.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'outer_lr': trial.suggest_loguniform('outer_lr', 1e-4, 1e-2),\n",
      "[W 2025-02-11 13:07:21,521] Trial 0 failed with parameters: {'inner_lr': 0.009807532962362663, 'outer_lr': 0.0012354211261741675, 'inner_steps': 5, 'layers': 3, 'neurons': 32} because of the following error: NameError(\"name 'train_tasks' is not defined\").\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_16156\\1450247049.py\", line 13, in objective\n",
      "    maml_train(model, train_tasks, params['inner_lr'], params['inner_steps'], params['outer_lr'], epochs=10)\n",
      "                      ^^^^^^^^^^^\n",
      "NameError: name 'train_tasks' is not defined\n",
      "[W 2025-02-11 13:07:21,524] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_tasks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sharpe\n\u001b[0;32m     17\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[7], line 13\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m      4\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner_lr\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_loguniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner_lr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1e-5\u001b[39m, \u001b[38;5;241m1e-2\u001b[39m),\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mouter_lr\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_loguniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mouter_lr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1e-4\u001b[39m, \u001b[38;5;241m1e-2\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneurons\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneurons\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m128\u001b[39m])\n\u001b[0;32m     10\u001b[0m }\n\u001b[0;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m TradingModel(input_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m, num_layers\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayers\u001b[39m\u001b[38;5;124m'\u001b[39m], hidden_units\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneurons\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 13\u001b[0m maml_train(model, \u001b[43mtrain_tasks\u001b[49m, params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner_lr\u001b[39m\u001b[38;5;124m'\u001b[39m], params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner_steps\u001b[39m\u001b[38;5;124m'\u001b[39m], params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mouter_lr\u001b[39m\u001b[38;5;124m'\u001b[39m], epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     14\u001b[0m sharpe \u001b[38;5;241m=\u001b[39m evaluate(model, val_tasks)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sharpe\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_tasks' is not defined"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'inner_lr': trial.suggest_loguniform('inner_lr', 1e-5, 1e-2),\n",
    "        'outer_lr': trial.suggest_loguniform('outer_lr', 1e-4, 1e-2),\n",
    "        'inner_steps': trial.suggest_int('inner_steps', 1, 5),\n",
    "        'layers': trial.suggest_int('layers', 2, 4),\n",
    "        'neurons': trial.suggest_categorical('neurons', [32, 64, 128])\n",
    "    }\n",
    "    \n",
    "    model = TradingModel(input_dim=12, num_layers=params['layers'], hidden_units=params['neurons'])\n",
    "    maml_train(model, train_tasks, params['inner_lr'], params['inner_steps'], params['outer_lr'], epochs=10)\n",
    "    sharpe = evaluate(model, val_tasks)\n",
    "    return sharpe\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(model, test_tasks):\n",
    "    results = []\n",
    "    for task in test_tasks:\n",
    "        # Adapt model to task\n",
    "        adapted_model = adapt_model(model, task['support'])\n",
    "        \n",
    "        # Generate signals\n",
    "        signals = generate_signals(adapted_model, task['data'])\n",
    "        \n",
    "        # Calculate returns\n",
    "        returns = calculate_returns(signals, task['data']['close'])\n",
    "        \n",
    "        # Compute metrics\n",
    "        results.append({\n",
    "            'sharpe': sharpe_ratio(returns),\n",
    "            'sortino': sortino_ratio(returns),\n",
    "            'max_drawdown': max_drawdown(returns),\n",
    "            'profit_factor': profit_factor(returns)\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe_ratio(returns, risk_free_rate=0):\n",
    "    excess_returns = returns - risk_free_rate\n",
    "    return excess_returns.mean() / excess_returns.std()\n",
    "\n",
    "def sortino_ratio(returns, risk_free_rate=0):\n",
    "    downside_returns = returns[returns < 0]\n",
    "    return (returns.mean() - risk_free_rate) / downside_returns.std()\n",
    "\n",
    "def max_drawdown(returns):\n",
    "    cumulative = (1 + returns).cumprod()\n",
    "    peak = cumulative.expanding(min_periods=1).max()\n",
    "    return (cumulative / peak - 1).min()\n",
    "\n",
    "def profit_factor(returns):\n",
    "    gains = returns[returns > 0].sum()\n",
    "    losses = -returns[returns < 0].sum()\n",
    "    return gains / losses if losses != 0 else float('inf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
