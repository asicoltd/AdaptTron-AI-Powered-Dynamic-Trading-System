{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ccxt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "import talib\n",
    "import requests\n",
    "from gym import spaces, Env\n",
    "\n",
    "# Configuration\n",
    "INITIAL_BALANCE = 10.0\n",
    "TRADING_FEE = 0.10  # 10%\n",
    "LOOKBACK_WINDOW = 60  # 60 periods (5 hours)\n",
    "INDICATOR_WINDOW = 14\n",
    "url = \"https://api.binance.com/api/v3/klines\"\n",
    "params = {\n",
    "    'symbol': 'BTCUSDT',  # The trading pair\n",
    "    'interval': '1m',     # 1-minute candlesticks\n",
    "    'limit': 1000        # Number of data points to fetch\n",
    "}\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "data = response.json()\n",
    "\n",
    "if response.status_code == 200:\n",
    "    df = pd.DataFrame(\n",
    "        data,\n",
    "        columns=['timestamp', 'open', 'high', 'low', 'close', 'volume', \n",
    "                    'close_time', 'quote_asset_volume', 'number_of_trades', \n",
    "                    'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore']\n",
    "    )\n",
    "    df = df[['timestamp', 'open', 'high', 'low', 'close', 'volume']]\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    df = df.astype(float)\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}, {response.text}\")\n",
    "data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         open      high       low     close   volume  \\\n",
      "timestamp                                                              \n",
      "2025-02-11 06:37:00  98329.01  98340.77  98326.72  98332.93  3.85294   \n",
      "2025-02-11 06:38:00  98332.94  98338.64  98332.93  98338.64  3.39168   \n",
      "2025-02-11 06:39:00  98338.63  98338.64  98338.63  98338.64  4.10685   \n",
      "2025-02-11 06:40:00  98338.64  98338.64  98303.74  98303.75  8.58922   \n",
      "2025-02-11 06:41:00  98303.75  98303.75  98303.74  98303.74  2.48335   \n",
      "\n",
      "                         SMA_50        EMA_20     ADX_14  Tenkan-sen  \\\n",
      "timestamp                                                              \n",
      "2025-02-11 06:37:00  98273.4250  98287.430041  17.284300   98291.705   \n",
      "2025-02-11 06:38:00  98275.1108  98292.307180  16.252269   98291.705   \n",
      "2025-02-11 06:39:00  98277.2172  98296.719830  16.920347   98291.705   \n",
      "2025-02-11 06:40:00  98279.2832  98297.389370  16.697497   98297.175   \n",
      "2025-02-11 06:41:00  98281.2322  98297.994192  17.437856   98304.750   \n",
      "\n",
      "                     Kijun-sen  ...  MACD_Signal    Stoch_K    Stoch_D  \\\n",
      "timestamp                       ...                                      \n",
      "2025-02-11 06:37:00   98240.19  ...    12.858302  88.887841  91.362450   \n",
      "2025-02-11 06:38:00   98240.19  ...    14.467317  94.274125  89.453825   \n",
      "2025-02-11 06:39:00   98240.19  ...    15.958144  94.274125  92.478697   \n",
      "2025-02-11 06:40:00   98240.19  ...    16.703719  61.362136  83.303462   \n",
      "2025-02-11 06:41:00   98240.19  ...    16.904869  61.352703  72.329654   \n",
      "\n",
      "                           OBV          VWAP      BB_Upper      BB_Lower  \\\n",
      "timestamp                                                                  \n",
      "2025-02-11 06:37:00  303.96400  97539.086972  98365.814180  98201.531820   \n",
      "2025-02-11 06:38:00  307.35568  97539.349793  98358.307582  98225.859418   \n",
      "2025-02-11 06:39:00  307.35568  97539.667800  98355.378875  98241.702125   \n",
      "2025-02-11 06:40:00  298.76646  97540.303068  98355.746298  98244.226702   \n",
      "2025-02-11 06:41:00  296.28311  97540.486540  98356.038553  98246.600447   \n",
      "\n",
      "                        ATR_14  Keltner_Upper  Keltner_Lower  \n",
      "timestamp                                                     \n",
      "2025-02-11 06:37:00  23.286429   98343.803041   98231.057041  \n",
      "2025-02-11 06:38:00  22.825000   98348.001180   98236.613180  \n",
      "2025-02-11 06:39:00  20.762143   98348.506830   98244.932830  \n",
      "2025-02-11 06:40:00  22.294286   98346.132370   98248.646370  \n",
      "2025-02-11 06:41:00  20.480714   98345.016192   98250.972192  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define Indicator Functions\n",
    "def SMA(data, period=14, column='close'):\n",
    "    return data[column].rolling(window=period).mean()\n",
    "\n",
    "def EMA(data, period=14, column='close'):\n",
    "    return data[column].ewm(span=period, adjust=False).mean()\n",
    "\n",
    "def ADX(data, period=14):\n",
    "    high, low, close = data['high'], data['low'], data['close']\n",
    "    plus_dm = high.diff().clip(lower=0)\n",
    "    minus_dm = -low.diff().clip(upper=0)\n",
    "    tr = pd.concat([high - low, abs(high - close.shift(1)), abs(low - close.shift(1))], axis=1).max(axis=1)\n",
    "    atr = tr.rolling(window=period).mean()\n",
    "    plus_di = 100 * (plus_dm.ewm(span=period, adjust=False).mean() / atr)\n",
    "    minus_di = abs(100 * (minus_dm.ewm(span=period, adjust=False).mean() / atr))\n",
    "    dx = (abs(plus_di - minus_di) / (plus_di + minus_di)) * 100\n",
    "    return dx.rolling(window=period).mean().dropna()\n",
    "\n",
    "def calculate_di(data, period=14):\n",
    "    high = data['high']\n",
    "    low = data['low']\n",
    "    close = data['close']\n",
    "\n",
    "    # Calculate the Directional Movement (DM)\n",
    "    plus_dm = high.diff().clip(lower=0)\n",
    "    minus_dm = -low.diff().clip(upper=0)\n",
    "\n",
    "    # True Range (TR)\n",
    "    tr = pd.concat([high - low, abs(high - close.shift(1)), abs(low - close.shift(1))], axis=1).max(axis=1)\n",
    "\n",
    "    # Smooth the DM and TR over the period\n",
    "    smoothed_plus_dm = plus_dm.rolling(window=period).sum()\n",
    "    smoothed_minus_dm = minus_dm.rolling(window=period).sum()\n",
    "    smoothed_tr = tr.rolling(window=period).sum()\n",
    "\n",
    "    # Calculate +DI and -DI\n",
    "    data['+DI'] = (smoothed_plus_dm / smoothed_tr) * 100\n",
    "    data['-DI'] = (smoothed_minus_dm / smoothed_tr) * 100\n",
    "    \n",
    "    return data[['+DI', '-DI']].dropna()\n",
    "\n",
    "def Ichimoku(data):\n",
    "    data = data.copy()\n",
    "    high, low = data['high'], data['low']\n",
    "\n",
    "    data['Tenkan-sen'] = (high.rolling(window=9).max() + low.rolling(window=9).min()) / 2\n",
    "    data['Kijun-sen'] = (high.rolling(window=26).max() + low.rolling(window=26).min()) / 2\n",
    "    data['Senkou Span A'] = ((data['Tenkan-sen'] + data['Kijun-sen']) / 2).shift(26)\n",
    "    data['Senkou Span B'] = ((high.rolling(window=52).max() + low.rolling(window=52).min()) / 2).shift(26)\n",
    "    data['Chikou Span'] = data['close'].shift(-26)\n",
    "\n",
    "    # Ensure all missing values are handled properly\n",
    "    return data[['Tenkan-sen', 'Kijun-sen', 'Senkou Span A', 'Senkou Span B', 'Chikou Span']].dropna()\n",
    "\n",
    "\n",
    "def RSI(data, period=14, column='close'):\n",
    "    delta = data[column].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
    "    rs = gain / loss\n",
    "    return (100 - (100 / (1 + rs))).dropna()\n",
    "\n",
    "def MACD(data, short_period=12, long_period=26, signal_period=9):\n",
    "    short_ema = EMA(data, short_period)\n",
    "    long_ema = EMA(data, long_period)\n",
    "    macd_line = short_ema - long_ema\n",
    "    signal_line = macd_line.ewm(span=signal_period, adjust=False).mean()\n",
    "    return macd_line.dropna(), signal_line.dropna()\n",
    "\n",
    "def Stochastic_Oscillator(data, period=14):\n",
    "    high, low, close = data['high'], data['low'], data['close']\n",
    "    lowest_low = low.rolling(window=period).min()\n",
    "    highest_high = high.rolling(window=period).max()\n",
    "    k = 100 * ((close - lowest_low) / (highest_high - lowest_low))\n",
    "    d = k.rolling(window=3).mean()\n",
    "    return k.dropna(), d.dropna()\n",
    "\n",
    "def OBV(data):\n",
    "    obv = (data['close'].diff().fillna(0) > 0) * data['volume'] - (data['close'].diff().fillna(0) < 0) * data['volume']\n",
    "    return obv.cumsum().dropna()\n",
    "\n",
    "def VWAP(data):\n",
    "    return ((data['close'] * data['volume']).cumsum() / data['volume'].cumsum()).dropna()\n",
    "\n",
    "def Bollinger_Bands(data, period=20):\n",
    "    sma = SMA(data, period)\n",
    "    std = data['close'].rolling(window=period).std()\n",
    "    upper_band = sma + (2 * std)\n",
    "    lower_band = sma - (2 * std)\n",
    "    return upper_band.dropna(), lower_band.dropna()\n",
    "\n",
    "def ATR(data, period=14):\n",
    "    high, low, close = data['high'], data['low'], data['close']\n",
    "    tr = pd.concat([\n",
    "        high - low, \n",
    "        abs(high - close.shift()), \n",
    "        abs(low - close.shift())\n",
    "    ], axis=1).max(axis=1)\n",
    "    return tr.rolling(window=period).mean().dropna()\n",
    "\n",
    "def Keltner_Channel(data, period=20):\n",
    "    ema = EMA(data, period)\n",
    "    atr = ATR(data, period)\n",
    "    upper_band = ema + (2 * atr)\n",
    "    lower_band = ema - (2 * atr)\n",
    "    return upper_band.dropna(), lower_band.dropna()\n",
    "# Ensure 'data' is a DataFrame\n",
    "if isinstance(data, list):\n",
    "    data = pd.DataFrame(data)\n",
    "\n",
    "# Calculate Indicators and Add to DataFrame\n",
    "data['SMA_50'] = SMA(data, 50)\n",
    "data['EMA_20'] = EMA(data, 20)\n",
    "data['ADX_14'] = ADX(data, 14)\n",
    "ichimoku = Ichimoku(data)\n",
    "data = pd.concat([data, ichimoku], axis=1)\n",
    "data[['+DI', '-DI']] = calculate_di(data, 14)\n",
    "data['RSI_14'] = RSI(data, 14)\n",
    "data['MACD'], data['MACD_Signal'] = MACD(data)\n",
    "data['Stoch_K'], data['Stoch_D'] = Stochastic_Oscillator(data)\n",
    "data['OBV'] = OBV(data)\n",
    "data['VWAP'] = VWAP(data)\n",
    "data['BB_Upper'], data['BB_Lower'] = Bollinger_Bands(data)\n",
    "data['ATR_14'] = ATR(data, 14)\n",
    "data['Keltner_Upper'], data['Keltner_Lower'] = Keltner_Channel(data)\n",
    "\n",
    "# Drop NaN values across all calculated indicators\n",
    "data = data.dropna()\n",
    "\n",
    "# Print the last few rows of the DataFrame\n",
    "print(data.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp\n",
       "2025-02-10 15:45:00    96869.191696\n",
       "2025-02-10 15:46:00    96881.094761\n",
       "2025-02-10 15:47:00    96881.789993\n",
       "2025-02-10 15:48:00    96880.945145\n",
       "2025-02-10 15:49:00    96878.166416\n",
       "                           ...     \n",
       "2025-02-11 06:37:00    98201.531820\n",
       "2025-02-11 06:38:00    98225.859418\n",
       "2025-02-11 06:39:00    98241.702125\n",
       "2025-02-11 06:40:00    98244.226702\n",
       "2025-02-11 06:41:00    98246.600447\n",
       "Freq: min, Name: BB_Lower, Length: 897, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['BB_Lower']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Trend Indicators ðŸ“ˆ (Detect Market Direction)\n",
    "(a) Simple Moving Average (SMA) & Exponential Moving Average (EMA)\n",
    "âœ… What It Detects:\n",
    "\n",
    "SMA: Long-term trend direction.\n",
    "EMA: Short-term trend with more weight on recent prices.\n",
    "ðŸ“Š How to Interpret Results:\n",
    "\n",
    "Price above SMA/EMA â†’ Uptrend (Bullish signal)\n",
    "Price below SMA/EMA â†’ Downtrend (Bearish signal)\n",
    "Golden Cross (50 EMA > 200 EMA) â†’ Strong Bullish\n",
    "Death Cross (50 EMA < 200 EMA) â†’ Strong Bearish\n",
    "(b) Average Directional Index (ADX)\n",
    "âœ… What It Detects:\n",
    "\n",
    "Strength of a trend (not direction).\n",
    "ðŸ“Š How to Interpret Results:\n",
    "\n",
    "ADX > 25 â†’ Strong trend (either bullish or bearish).\n",
    "ADX < 20 â†’ Weak trend (sideways movement).\n",
    "Increasing ADX â†’ Trend is gaining strength.\n",
    "Decreasing ADX â†’ Trend is weakening.\n",
    "(c) Ichimoku Cloud\n",
    "âœ… What It Detects:\n",
    "\n",
    "Trend direction, support/resistance, and momentum.\n",
    "ðŸ“Š How to Interpret Results:\n",
    "\n",
    "Price above the cloud â†’ Bullish trend.\n",
    "Price below the cloud â†’ Bearish trend.\n",
    "Price inside the cloud â†’ Consolidation/Uncertainty.\n",
    "2. Momentum Indicators ðŸš€ (Measure Strength of Price Movement)\n",
    "(a) Relative Strength Index (RSI)\n",
    "âœ… What It Detects:\n",
    "\n",
    "Overbought and oversold conditions (potential reversal points).\n",
    "ðŸ“Š How to Interpret Results:\n",
    "\n",
    "RSI > 70 â†’ Overbought (Sell signal).\n",
    "RSI < 30 â†’ Oversold (Buy signal).\n",
    "Divergence (Price rises but RSI falls) â†’ Weakening trend, possible reversal.\n",
    "(b) Moving Average Convergence Divergence (MACD)\n",
    "âœ… What It Detects:\n",
    "\n",
    "Trend direction, momentum, and reversals.\n",
    "ðŸ“Š How to Interpret Results:\n",
    "\n",
    "MACD line crosses above Signal line â†’ Bullish crossover (Buy).\n",
    "MACD line crosses below Signal line â†’ Bearish crossover (Sell).\n",
    "MACD Divergence â†’ Price making higher highs while MACD falls â†’ Possible trend reversal.\n",
    "(c) Stochastic Oscillator\n",
    "âœ… What It Detects:\n",
    "\n",
    "Momentum shifts and overbought/oversold conditions.\n",
    "ðŸ“Š How to Interpret Results:\n",
    "\n",
    "%K > 80 â†’ Overbought (Sell signal).\n",
    "%K < 20 â†’ Oversold (Buy signal).\n",
    "%K crossing %D from below â†’ Bullish reversal.\n",
    "%K crossing %D from above â†’ Bearish reversal.\n",
    "3. Volume Indicators ðŸ“Š (Confirm Market Strength)\n",
    "(a) On-Balance Volume (OBV)\n",
    "âœ… What It Detects:\n",
    "\n",
    "Buying vs. selling pressure.\n",
    "ðŸ“Š How to Interpret Results:\n",
    "\n",
    "Rising OBV â†’ Buying pressure (Bullish).\n",
    "Falling OBV â†’ Selling pressure (Bearish).\n",
    "Divergence (Price rising, OBV falling) â†’ Weak uptrend, possible reversal.\n",
    "(b) Volume Weighted Average Price (VWAP)\n",
    "âœ… What It Detects:\n",
    "\n",
    "Trend strength based on volume-weighted prices.\n",
    "ðŸ“Š How to Interpret Results:\n",
    "\n",
    "Price above VWAP â†’ Strong bullish trend.\n",
    "Price below VWAP â†’ Strong bearish trend.\n",
    "VWAP flat â†’ Market is ranging (no clear trend).\n",
    "4. Volatility Indicators âš¡ (Measure Market Risk & Big Moves)\n",
    "(a) Bollinger Bands (BB)\n",
    "âœ… What It Detects:\n",
    "\n",
    "Volatility and potential breakouts.\n",
    "ðŸ“Š How to Interpret Results:\n",
    "\n",
    "Price touches upper band â†’ Overbought (Sell signal).\n",
    "Price touches lower band â†’ Oversold (Buy signal).\n",
    "Bands expand â†’ Increased volatility (Big move expected).\n",
    "Bands contract â†’ Low volatility (Possible breakout).\n",
    "(b) Average True Range (ATR)\n",
    "âœ… What It Detects:\n",
    "\n",
    "Market volatility (size of price movements).\n",
    "ðŸ“Š How to Interpret Results:\n",
    "\n",
    "High ATR â†’ High volatility (Big price swings).\n",
    "Low ATR â†’ Low volatility (Stable price movement).\n",
    "Rising ATR â†’ Market getting volatile (Breakout possible).\n",
    "(c) Keltner Channel\n",
    "âœ… What It Detects:\n",
    "\n",
    "Trend direction and volatility.\n",
    "ðŸ“Š How to Interpret Results:\n",
    "\n",
    "Price above upper band â†’ Strong bullish move.\n",
    "Price below lower band â†’ Strong bearish move.\n",
    "Price inside the bands â†’ Normal market behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strategy Type >\tBest Indicator Combinations <br>\n",
    "Trend-Following >\tEMA + ADX + Ichimoku Cloud<br>\n",
    "Momentum-Based >\tRSI + MACD + Stochastic Oscillator<br>\n",
    "Breakout Trading >\tBollinger Bands + ATR + OBV<br>\n",
    "Mean Reversion >\tRSI + Bollinger Bands + VWAP<br>\n",
    "Scalping/Day Trading >\tVWAP + Stochastic RSI + Volume<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMA bullish\n",
      "EMA bullish\n",
      "ADX neutral\n",
      "Ichimoku bullish\n",
      "RSI bullish\n",
      "MACD bullish\n",
      "Stochastic Oscillator bearish\n",
      "OBV bearish\n",
      "VWAP bullish\n",
      "Bollinger Bands neutral\n",
      "ATR bearish\n",
      "Keltner Channel neutral\n",
      "6 3 3\n",
      "Final Prediction: bullish\n"
     ]
    }
   ],
   "source": [
    "def get_signal(data):\n",
    "    signals = []\n",
    "    indicators = ['SMA','EMA','ADX','Ichimoku','RSI','MACD','Stochastic Oscillator','OBV','VWAP','Bollinger Bands','ATR','Keltner Channel']\n",
    "    # SMA\n",
    "    if data['close'].iloc[-1] > data['SMA_50'].iloc[-1]:\n",
    "        signals.append('bullish')\n",
    "    elif data['close'].iloc[-1] < data['SMA_50'].iloc[-1]:\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "\n",
    "    # EMA\n",
    "    if data['close'].iloc[-1] > data['EMA_20'].iloc[-1]:\n",
    "        signals.append('bullish')\n",
    "    elif data['close'].iloc[-1] < data['EMA_20'].iloc[-1]:\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "\n",
    "    # ADX\n",
    "    if data['ADX_14'].iloc[-1] > 25 and data['+DI'].iloc[-1] > data['-DI'].iloc[-1]:\n",
    "        signals.append('bullish')\n",
    "    elif data['ADX_14'].iloc[-1] > 25 and data['+DI'].iloc[-1] < data['-DI'].iloc[-1]:\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "\n",
    "    # Ichimoku\n",
    "    if data['close'].iloc[-1] > data['Senkou Span A'].iloc[-1] and data['Tenkan-sen'].iloc[-1] > data['Kijun-sen'].iloc[-1]:\n",
    "        signals.append('bullish')\n",
    "    elif data['close'].iloc[-1] < data['Senkou Span A'].iloc[-1] and data['Tenkan-sen'].iloc[-1] < data['Kijun-sen'].iloc[-1]:\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "\n",
    "    # RSI\n",
    "    if data['RSI_14'].iloc[-1] < 30 or data['RSI_14'].iloc[-1] > 50:\n",
    "        signals.append('bullish')\n",
    "    elif data['RSI_14'].iloc[-1] > 30 or data['RSI_14'].iloc[-1] < 50:\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "\n",
    "    # MACD\n",
    "    if data['MACD'].iloc[-1] > data['MACD_Signal'].iloc[-1]:\n",
    "        signals.append('bullish')\n",
    "    elif data['MACD'].iloc[-1] < data['MACD_Signal'].iloc[-1]:\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "\n",
    "    # Stochastic Oscillator\n",
    "    if data['Stoch_K'].iloc[-1] > data['Stoch_D'].iloc[-1] and data['Stoch_K'].iloc[-1] < 20:\n",
    "        signals.append('bullish')\n",
    "    elif data['Stoch_K'].iloc[-1] < data['Stoch_D'].iloc[-1] and data['Stoch_K'].iloc[-1] > 20:\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "\n",
    "    # OBV\n",
    "    if data['OBV'].iloc[-1] > data['OBV'].iloc[-2]:  # OBV rising\n",
    "        signals.append('bullish')\n",
    "    elif data['OBV'].iloc[-1] < data['OBV'].iloc[-2]:\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "\n",
    "    # VWAP\n",
    "    if data['close'].iloc[-1] > data['VWAP'].iloc[-1]:\n",
    "        signals.append('bullish')\n",
    "    elif data['close'].iloc[-1] < data['VWAP'].iloc[-1]:\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "\n",
    "    # Bollinger Bands\n",
    "    if data['close'].iloc[-1] < data['BB_Lower'].iloc[-1]:  # Touching lower band\n",
    "        signals.append('bullish')\n",
    "    elif data['close'].iloc[-1] > data['BB_Upper'].iloc[-1]:  # Touching upper band\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "\n",
    "    # ATR (Volatility Expansion)\n",
    "    if data['ATR_14'].iloc[-1] > data['ATR_14'].iloc[-2]:  # ATR increasing\n",
    "        signals.append('bullish')\n",
    "    elif data['ATR_14'].iloc[-1] < data['ATR_14'].iloc[-2]:\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "\n",
    "    # Keltner Channel\n",
    "    if data['close'].iloc[-1] > data['Keltner_Upper'].iloc[-1]:\n",
    "        signals.append('bullish')\n",
    "    elif data['close'].iloc[-1] < data['Keltner_Lower'].iloc[-1]:\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "        \n",
    "\n",
    "    # Count bullish and bearish signals\n",
    "    bullish_count = signals.count('bullish')\n",
    "    bearish_count = signals.count('bearish')\n",
    "    for i in range(len(indicators)):\n",
    "        print(indicators[i]+' '+signals[i])\n",
    "    print(bullish_count,bearish_count,len(signals)-bullish_count-bearish_count)\n",
    "    # Final prediction\n",
    "    if bullish_count > bearish_count:\n",
    "        return 'bullish'\n",
    "    elif bearish_count > bullish_count:\n",
    "        return 'bearish'\n",
    "    else:\n",
    "        return 'neutral'  # When there's a tie or no clear trend\n",
    "    \n",
    "\n",
    "# Example: Get the final signal for the most recent data\n",
    "signal = get_signal(data)\n",
    "print(f\"Final Prediction: {signal}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TradingModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_layers=3, hidden_units=64):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for _ in range(num_layers):\n",
    "            layers.append(nn.Linear(input_dim, hidden_units))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = hidden_units\n",
    "        layers.append(nn.Linear(hidden_units, 1))  # Predict return\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maml_train(model, tasks, inner_lr, inner_steps, outer_lr, epochs):\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=outer_lr)\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for task in tasks:\n",
    "            # Clone model for inner loop\n",
    "            fast_weights = dict(model.named_parameters())\n",
    "            \n",
    "            # Inner loop adaptation\n",
    "            for _ in range(inner_steps):\n",
    "                loss = compute_loss(task['support'], model, fast_weights)\n",
    "                grads = torch.autograd.grad(loss, fast_weights.values())\n",
    "                fast_weights = {name: param - inner_lr * grad \n",
    "                               for (name, param), grad in zip(fast_weights.items(), grads)}\n",
    "            \n",
    "            # Compute query loss and backprop\n",
    "            query_loss = compute_loss(task['query'], model, fast_weights)\n",
    "            total_loss += query_loss\n",
    "            query_loss.backward()\n",
    "        \n",
    "        # Outer optimization step\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-02-11 13:07:21,511] A new study created in memory with name: no-name-6ff007ee-e3a2-4df7-b834-fef408445eb8\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_16156\\1450247049.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'inner_lr': trial.suggest_loguniform('inner_lr', 1e-5, 1e-2),\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_16156\\1450247049.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'outer_lr': trial.suggest_loguniform('outer_lr', 1e-4, 1e-2),\n",
      "[W 2025-02-11 13:07:21,521] Trial 0 failed with parameters: {'inner_lr': 0.009807532962362663, 'outer_lr': 0.0012354211261741675, 'inner_steps': 5, 'layers': 3, 'neurons': 32} because of the following error: NameError(\"name 'train_tasks' is not defined\").\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_16156\\1450247049.py\", line 13, in objective\n",
      "    maml_train(model, train_tasks, params['inner_lr'], params['inner_steps'], params['outer_lr'], epochs=10)\n",
      "                      ^^^^^^^^^^^\n",
      "NameError: name 'train_tasks' is not defined\n",
      "[W 2025-02-11 13:07:21,524] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_tasks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sharpe\n\u001b[0;32m     17\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[7], line 13\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m      4\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner_lr\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_loguniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner_lr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1e-5\u001b[39m, \u001b[38;5;241m1e-2\u001b[39m),\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mouter_lr\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_loguniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mouter_lr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1e-4\u001b[39m, \u001b[38;5;241m1e-2\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneurons\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneurons\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m128\u001b[39m])\n\u001b[0;32m     10\u001b[0m }\n\u001b[0;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m TradingModel(input_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m, num_layers\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayers\u001b[39m\u001b[38;5;124m'\u001b[39m], hidden_units\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneurons\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 13\u001b[0m maml_train(model, \u001b[43mtrain_tasks\u001b[49m, params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner_lr\u001b[39m\u001b[38;5;124m'\u001b[39m], params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner_steps\u001b[39m\u001b[38;5;124m'\u001b[39m], params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mouter_lr\u001b[39m\u001b[38;5;124m'\u001b[39m], epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     14\u001b[0m sharpe \u001b[38;5;241m=\u001b[39m evaluate(model, val_tasks)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sharpe\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_tasks' is not defined"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'inner_lr': trial.suggest_loguniform('inner_lr', 1e-5, 1e-2),\n",
    "        'outer_lr': trial.suggest_loguniform('outer_lr', 1e-4, 1e-2),\n",
    "        'inner_steps': trial.suggest_int('inner_steps', 1, 5),\n",
    "        'layers': trial.suggest_int('layers', 2, 4),\n",
    "        'neurons': trial.suggest_categorical('neurons', [32, 64, 128])\n",
    "    }\n",
    "    \n",
    "    model = TradingModel(input_dim=12, num_layers=params['layers'], hidden_units=params['neurons'])\n",
    "    maml_train(model, train_tasks, params['inner_lr'], params['inner_steps'], params['outer_lr'], epochs=10)\n",
    "    sharpe = evaluate(model, val_tasks)\n",
    "    return sharpe\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(model, test_tasks):\n",
    "    results = []\n",
    "    for task in test_tasks:\n",
    "        # Adapt model to task\n",
    "        adapted_model = adapt_model(model, task['support'])\n",
    "        \n",
    "        # Generate signals\n",
    "        signals = generate_signals(adapted_model, task['data'])\n",
    "        \n",
    "        # Calculate returns\n",
    "        returns = calculate_returns(signals, task['data']['close'])\n",
    "        \n",
    "        # Compute metrics\n",
    "        results.append({\n",
    "            'sharpe': sharpe_ratio(returns),\n",
    "            'sortino': sortino_ratio(returns),\n",
    "            'max_drawdown': max_drawdown(returns),\n",
    "            'profit_factor': profit_factor(returns)\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe_ratio(returns, risk_free_rate=0):\n",
    "    excess_returns = returns - risk_free_rate\n",
    "    return excess_returns.mean() / excess_returns.std()\n",
    "\n",
    "def sortino_ratio(returns, risk_free_rate=0):\n",
    "    downside_returns = returns[returns < 0]\n",
    "    return (returns.mean() - risk_free_rate) / downside_returns.std()\n",
    "\n",
    "def max_drawdown(returns):\n",
    "    cumulative = (1 + returns).cumprod()\n",
    "    peak = cumulative.expanding(min_periods=1).max()\n",
    "    return (cumulative / peak - 1).min()\n",
    "\n",
    "def profit_factor(returns):\n",
    "    gains = returns[returns > 0].sum()\n",
    "    losses = -returns[returns < 0].sum()\n",
    "    return gains / losses if losses != 0 else float('inf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
