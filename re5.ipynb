{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ccxt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "import talib\n",
    "import requests\n",
    "from gym import spaces, Env\n",
    "\n",
    "# Configuration\n",
    "INITIAL_BALANCE = 10.0\n",
    "TRADING_FEE = 0.10  # 10%\n",
    "LOOKBACK_WINDOW = 60  # 60 periods (5 hours)\n",
    "INDICATOR_WINDOW = 14\n",
    "url = \"https://api.binance.com/api/v3/klines\"\n",
    "params = {\n",
    "    'symbol': 'BTCUSDT',  # The trading pair\n",
    "    'interval': '1m',     # 1-minute candlesticks\n",
    "    'limit': 1000        # Number of data points to fetch\n",
    "}\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "data = response.json()\n",
    "\n",
    "if response.status_code == 200:\n",
    "    df = pd.DataFrame(\n",
    "        data,\n",
    "        columns=['timestamp', 'open', 'high', 'low', 'close', 'volume', \n",
    "                    'close_time', 'quote_asset_volume', 'number_of_trades', \n",
    "                    'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore']\n",
    "    )\n",
    "    df = df[['timestamp', 'open', 'high', 'low', 'close', 'volume']]\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    df = df.astype(float)\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}, {response.text}\")\n",
    "data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         open      high       low     close   volume  \\\n",
      "timestamp                                                              \n",
      "2025-02-11 06:37:00  98329.01  98340.77  98326.72  98332.93  3.85294   \n",
      "2025-02-11 06:38:00  98332.94  98338.64  98332.93  98338.64  3.39168   \n",
      "2025-02-11 06:39:00  98338.63  98338.64  98338.63  98338.64  4.10685   \n",
      "2025-02-11 06:40:00  98338.64  98338.64  98303.74  98303.75  8.58922   \n",
      "2025-02-11 06:41:00  98303.75  98303.75  98303.74  98303.74  2.48335   \n",
      "\n",
      "                         SMA_50        EMA_20     ADX_14  Tenkan-sen  \\\n",
      "timestamp                                                              \n",
      "2025-02-11 06:37:00  98273.4250  98287.430041  17.284300   98291.705   \n",
      "2025-02-11 06:38:00  98275.1108  98292.307180  16.252269   98291.705   \n",
      "2025-02-11 06:39:00  98277.2172  98296.719830  16.920347   98291.705   \n",
      "2025-02-11 06:40:00  98279.2832  98297.389370  16.697497   98297.175   \n",
      "2025-02-11 06:41:00  98281.2322  98297.994192  17.437856   98304.750   \n",
      "\n",
      "                     Kijun-sen  ...  MACD_Signal    Stoch_K    Stoch_D  \\\n",
      "timestamp                       ...                                      \n",
      "2025-02-11 06:37:00   98240.19  ...    12.858302  88.887841  91.362450   \n",
      "2025-02-11 06:38:00   98240.19  ...    14.467317  94.274125  89.453825   \n",
      "2025-02-11 06:39:00   98240.19  ...    15.958144  94.274125  92.478697   \n",
      "2025-02-11 06:40:00   98240.19  ...    16.703719  61.362136  83.303462   \n",
      "2025-02-11 06:41:00   98240.19  ...    16.904869  61.352703  72.329654   \n",
      "\n",
      "                           OBV          VWAP      BB_Upper      BB_Lower  \\\n",
      "timestamp                                                                  \n",
      "2025-02-11 06:37:00  303.96400  97539.086972  98365.814180  98201.531820   \n",
      "2025-02-11 06:38:00  307.35568  97539.349793  98358.307582  98225.859418   \n",
      "2025-02-11 06:39:00  307.35568  97539.667800  98355.378875  98241.702125   \n",
      "2025-02-11 06:40:00  298.76646  97540.303068  98355.746298  98244.226702   \n",
      "2025-02-11 06:41:00  296.28311  97540.486540  98356.038553  98246.600447   \n",
      "\n",
      "                        ATR_14  Keltner_Upper  Keltner_Lower  \n",
      "timestamp                                                     \n",
      "2025-02-11 06:37:00  23.286429   98343.803041   98231.057041  \n",
      "2025-02-11 06:38:00  22.825000   98348.001180   98236.613180  \n",
      "2025-02-11 06:39:00  20.762143   98348.506830   98244.932830  \n",
      "2025-02-11 06:40:00  22.294286   98346.132370   98248.646370  \n",
      "2025-02-11 06:41:00  20.480714   98345.016192   98250.972192  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define Indicator Functions\n",
    "def SMA(data, period=14, column='close'):\n",
    "    return data[column].rolling(window=period).mean()\n",
    "\n",
    "def EMA(data, period=14, column='close'):\n",
    "    return data[column].ewm(span=period, adjust=False).mean()\n",
    "\n",
    "def ADX(data, period=14):\n",
    "    high, low, close = data['high'], data['low'], data['close']\n",
    "    plus_dm = high.diff().clip(lower=0)\n",
    "    minus_dm = -low.diff().clip(upper=0)\n",
    "    tr = pd.concat([high - low, abs(high - close.shift(1)), abs(low - close.shift(1))], axis=1).max(axis=1)\n",
    "    atr = tr.rolling(window=period).mean()\n",
    "    plus_di = 100 * (plus_dm.ewm(span=period, adjust=False).mean() / atr)\n",
    "    minus_di = abs(100 * (minus_dm.ewm(span=period, adjust=False).mean() / atr))\n",
    "    dx = (abs(plus_di - minus_di) / (plus_di + minus_di)) * 100\n",
    "    return dx.rolling(window=period).mean().dropna()\n",
    "\n",
    "def calculate_di(data, period=14):\n",
    "    high = data['high']\n",
    "    low = data['low']\n",
    "    close = data['close']\n",
    "\n",
    "    # Calculate the Directional Movement (DM)\n",
    "    plus_dm = high.diff().clip(lower=0)\n",
    "    minus_dm = -low.diff().clip(upper=0)\n",
    "\n",
    "    # True Range (TR)\n",
    "    tr = pd.concat([high - low, abs(high - close.shift(1)), abs(low - close.shift(1))], axis=1).max(axis=1)\n",
    "\n",
    "    # Smooth the DM and TR over the period\n",
    "    smoothed_plus_dm = plus_dm.rolling(window=period).sum()\n",
    "    smoothed_minus_dm = minus_dm.rolling(window=period).sum()\n",
    "    smoothed_tr = tr.rolling(window=period).sum()\n",
    "\n",
    "    # Calculate +DI and -DI\n",
    "    data['+DI'] = (smoothed_plus_dm / smoothed_tr) * 100\n",
    "    data['-DI'] = (smoothed_minus_dm / smoothed_tr) * 100\n",
    "    \n",
    "    return data[['+DI', '-DI']].dropna()\n",
    "\n",
    "def Ichimoku(data):\n",
    "    data = data.copy()\n",
    "    high, low = data['high'], data['low']\n",
    "\n",
    "    data['Tenkan-sen'] = (high.rolling(window=9).max() + low.rolling(window=9).min()) / 2\n",
    "    data['Kijun-sen'] = (high.rolling(window=26).max() + low.rolling(window=26).min()) / 2\n",
    "    data['Senkou Span A'] = ((data['Tenkan-sen'] + data['Kijun-sen']) / 2).shift(26)\n",
    "    data['Senkou Span B'] = ((high.rolling(window=52).max() + low.rolling(window=52).min()) / 2).shift(26)\n",
    "    data['Chikou Span'] = data['close'].shift(-26)\n",
    "\n",
    "    # Ensure all missing values are handled properly\n",
    "    return data[['Tenkan-sen', 'Kijun-sen', 'Senkou Span A', 'Senkou Span B', 'Chikou Span']].dropna()\n",
    "\n",
    "\n",
    "def RSI(data, period=14, column='close'):\n",
    "    delta = data[column].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
    "    rs = gain / loss\n",
    "    return (100 - (100 / (1 + rs))).dropna()\n",
    "\n",
    "def MACD(data, short_period=12, long_period=26, signal_period=9):\n",
    "    short_ema = EMA(data, short_period)\n",
    "    long_ema = EMA(data, long_period)\n",
    "    macd_line = short_ema - long_ema\n",
    "    signal_line = macd_line.ewm(span=signal_period, adjust=False).mean()\n",
    "    return macd_line.dropna(), signal_line.dropna()\n",
    "\n",
    "def Stochastic_Oscillator(data, period=14):\n",
    "    high, low, close = data['high'], data['low'], data['close']\n",
    "    lowest_low = low.rolling(window=period).min()\n",
    "    highest_high = high.rolling(window=period).max()\n",
    "    k = 100 * ((close - lowest_low) / (highest_high - lowest_low))\n",
    "    d = k.rolling(window=3).mean()\n",
    "    return k.dropna(), d.dropna()\n",
    "\n",
    "def OBV(data):\n",
    "    obv = (data['close'].diff().fillna(0) > 0) * data['volume'] - (data['close'].diff().fillna(0) < 0) * data['volume']\n",
    "    return obv.cumsum().dropna()\n",
    "\n",
    "def VWAP(data):\n",
    "    return ((data['close'] * data['volume']).cumsum() / data['volume'].cumsum()).dropna()\n",
    "\n",
    "def Bollinger_Bands(data, period=20):\n",
    "    sma = SMA(data, period)\n",
    "    std = data['close'].rolling(window=period).std()\n",
    "    upper_band = sma + (2 * std)\n",
    "    lower_band = sma - (2 * std)\n",
    "    return upper_band.dropna(), lower_band.dropna()\n",
    "\n",
    "def ATR(data, period=14):\n",
    "    high, low, close = data['high'], data['low'], data['close']\n",
    "    tr = pd.concat([\n",
    "        high - low, \n",
    "        abs(high - close.shift()), \n",
    "        abs(low - close.shift())\n",
    "    ], axis=1).max(axis=1)\n",
    "    return tr.rolling(window=period).mean().dropna()\n",
    "\n",
    "def Keltner_Channel(data, period=20):\n",
    "    ema = EMA(data, period)\n",
    "    atr = ATR(data, period)\n",
    "    upper_band = ema + (2 * atr)\n",
    "    lower_band = ema - (2 * atr)\n",
    "    return upper_band.dropna(), lower_band.dropna()\n",
    "# Ensure 'data' is a DataFrame\n",
    "if isinstance(data, list):\n",
    "    data = pd.DataFrame(data)\n",
    "\n",
    "# Calculate Indicators and Add to DataFrame\n",
    "data['SMA_50'] = SMA(data, 50)\n",
    "data['EMA_20'] = EMA(data, 20)\n",
    "data['ADX_14'] = ADX(data, 14)\n",
    "ichimoku = Ichimoku(data)\n",
    "data = pd.concat([data, ichimoku], axis=1)\n",
    "data[['+DI', '-DI']] = calculate_di(data, 14)\n",
    "data['RSI_14'] = RSI(data, 14)\n",
    "data['MACD'], data['MACD_Signal'] = MACD(data)\n",
    "data['Stoch_K'], data['Stoch_D'] = Stochastic_Oscillator(data)\n",
    "data['OBV'] = OBV(data)\n",
    "data['VWAP'] = VWAP(data)\n",
    "data['BB_Upper'], data['BB_Lower'] = Bollinger_Bands(data)\n",
    "data['ATR_14'] = ATR(data, 14)\n",
    "data['Keltner_Upper'], data['Keltner_Lower'] = Keltner_Channel(data)\n",
    "\n",
    "# Drop NaN values across all calculated indicators\n",
    "data = data.dropna()\n",
    "\n",
    "# Print the last few rows of the DataFrame\n",
    "print(data.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp\n",
       "2025-02-10 15:45:00    96869.191696\n",
       "2025-02-10 15:46:00    96881.094761\n",
       "2025-02-10 15:47:00    96881.789993\n",
       "2025-02-10 15:48:00    96880.945145\n",
       "2025-02-10 15:49:00    96878.166416\n",
       "                           ...     \n",
       "2025-02-11 06:37:00    98201.531820\n",
       "2025-02-11 06:38:00    98225.859418\n",
       "2025-02-11 06:39:00    98241.702125\n",
       "2025-02-11 06:40:00    98244.226702\n",
       "2025-02-11 06:41:00    98246.600447\n",
       "Freq: min, Name: BB_Lower, Length: 897, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['BB_Lower']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Trend Indicators 📈 (Detect Market Direction)\n",
    "(a) Simple Moving Average (SMA) & Exponential Moving Average (EMA)\n",
    "✅ What It Detects:\n",
    "\n",
    "SMA: Long-term trend direction.\n",
    "EMA: Short-term trend with more weight on recent prices.\n",
    "📊 How to Interpret Results:\n",
    "\n",
    "Price above SMA/EMA → Uptrend (Bullish signal)\n",
    "Price below SMA/EMA → Downtrend (Bearish signal)\n",
    "Golden Cross (50 EMA > 200 EMA) → Strong Bullish\n",
    "Death Cross (50 EMA < 200 EMA) → Strong Bearish\n",
    "(b) Average Directional Index (ADX)\n",
    "✅ What It Detects:\n",
    "\n",
    "Strength of a trend (not direction).\n",
    "📊 How to Interpret Results:\n",
    "\n",
    "ADX > 25 → Strong trend (either bullish or bearish).\n",
    "ADX < 20 → Weak trend (sideways movement).\n",
    "Increasing ADX → Trend is gaining strength.\n",
    "Decreasing ADX → Trend is weakening.\n",
    "(c) Ichimoku Cloud\n",
    "✅ What It Detects:\n",
    "\n",
    "Trend direction, support/resistance, and momentum.\n",
    "📊 How to Interpret Results:\n",
    "\n",
    "Price above the cloud → Bullish trend.\n",
    "Price below the cloud → Bearish trend.\n",
    "Price inside the cloud → Consolidation/Uncertainty.\n",
    "2. Momentum Indicators 🚀 (Measure Strength of Price Movement)\n",
    "(a) Relative Strength Index (RSI)\n",
    "✅ What It Detects:\n",
    "\n",
    "Overbought and oversold conditions (potential reversal points).\n",
    "📊 How to Interpret Results:\n",
    "\n",
    "RSI > 70 → Overbought (Sell signal).\n",
    "RSI < 30 → Oversold (Buy signal).\n",
    "Divergence (Price rises but RSI falls) → Weakening trend, possible reversal.\n",
    "(b) Moving Average Convergence Divergence (MACD)\n",
    "✅ What It Detects:\n",
    "\n",
    "Trend direction, momentum, and reversals.\n",
    "📊 How to Interpret Results:\n",
    "\n",
    "MACD line crosses above Signal line → Bullish crossover (Buy).\n",
    "MACD line crosses below Signal line → Bearish crossover (Sell).\n",
    "MACD Divergence → Price making higher highs while MACD falls → Possible trend reversal.\n",
    "(c) Stochastic Oscillator\n",
    "✅ What It Detects:\n",
    "\n",
    "Momentum shifts and overbought/oversold conditions.\n",
    "📊 How to Interpret Results:\n",
    "\n",
    "%K > 80 → Overbought (Sell signal).\n",
    "%K < 20 → Oversold (Buy signal).\n",
    "%K crossing %D from below → Bullish reversal.\n",
    "%K crossing %D from above → Bearish reversal.\n",
    "3. Volume Indicators 📊 (Confirm Market Strength)\n",
    "(a) On-Balance Volume (OBV)\n",
    "✅ What It Detects:\n",
    "\n",
    "Buying vs. selling pressure.\n",
    "📊 How to Interpret Results:\n",
    "\n",
    "Rising OBV → Buying pressure (Bullish).\n",
    "Falling OBV → Selling pressure (Bearish).\n",
    "Divergence (Price rising, OBV falling) → Weak uptrend, possible reversal.\n",
    "(b) Volume Weighted Average Price (VWAP)\n",
    "✅ What It Detects:\n",
    "\n",
    "Trend strength based on volume-weighted prices.\n",
    "📊 How to Interpret Results:\n",
    "\n",
    "Price above VWAP → Strong bullish trend.\n",
    "Price below VWAP → Strong bearish trend.\n",
    "VWAP flat → Market is ranging (no clear trend).\n",
    "4. Volatility Indicators ⚡ (Measure Market Risk & Big Moves)\n",
    "(a) Bollinger Bands (BB)\n",
    "✅ What It Detects:\n",
    "\n",
    "Volatility and potential breakouts.\n",
    "📊 How to Interpret Results:\n",
    "\n",
    "Price touches upper band → Overbought (Sell signal).\n",
    "Price touches lower band → Oversold (Buy signal).\n",
    "Bands expand → Increased volatility (Big move expected).\n",
    "Bands contract → Low volatility (Possible breakout).\n",
    "(b) Average True Range (ATR)\n",
    "✅ What It Detects:\n",
    "\n",
    "Market volatility (size of price movements).\n",
    "📊 How to Interpret Results:\n",
    "\n",
    "High ATR → High volatility (Big price swings).\n",
    "Low ATR → Low volatility (Stable price movement).\n",
    "Rising ATR → Market getting volatile (Breakout possible).\n",
    "(c) Keltner Channel\n",
    "✅ What It Detects:\n",
    "\n",
    "Trend direction and volatility.\n",
    "📊 How to Interpret Results:\n",
    "\n",
    "Price above upper band → Strong bullish move.\n",
    "Price below lower band → Strong bearish move.\n",
    "Price inside the bands → Normal market behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strategy Type >\tBest Indicator Combinations <br>\n",
    "Trend-Following >\tEMA + ADX + Ichimoku Cloud<br>\n",
    "Momentum-Based >\tRSI + MACD + Stochastic Oscillator<br>\n",
    "Breakout Trading >\tBollinger Bands + ATR + OBV<br>\n",
    "Mean Reversion >\tRSI + Bollinger Bands + VWAP<br>\n",
    "Scalping/Day Trading >\tVWAP + Stochastic RSI + Volume<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMA bullish\n",
      "EMA bullish\n",
      "ADX neutral\n",
      "Ichimoku bullish\n",
      "RSI bullish\n",
      "MACD bullish\n",
      "Stochastic Oscillator bearish\n",
      "OBV bearish\n",
      "VWAP bullish\n",
      "Bollinger Bands neutral\n",
      "ATR bearish\n",
      "Keltner Channel neutral\n",
      "6 3 3\n",
      "Final Prediction: bullish\n"
     ]
    }
   ],
   "source": [
    "def get_signal(data):\n",
    "    signals = []\n",
    "    indicators = ['SMA','EMA','ADX','Ichimoku','RSI','MACD','Stochastic Oscillator','OBV','VWAP','Bollinger Bands','ATR','Keltner Channel']\n",
    "    # SMA\n",
    "    if data['close'].iloc[-1] > data['SMA_50'].iloc[-1]:\n",
    "        signals.append('bullish')\n",
    "    elif data['close'].iloc[-1] < data['SMA_50'].iloc[-1]:\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "\n",
    "    # EMA\n",
    "    if data['close'].iloc[-1] > data['EMA_20'].iloc[-1]:\n",
    "        signals.append('bullish')\n",
    "    elif data['close'].iloc[-1] < data['EMA_20'].iloc[-1]:\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "\n",
    "    # ADX\n",
    "    if data['ADX_14'].iloc[-1] > 25 and data['+DI'].iloc[-1] > data['-DI'].iloc[-1]:\n",
    "        signals.append('bullish')\n",
    "    elif data['ADX_14'].iloc[-1] > 25 and data['+DI'].iloc[-1] < data['-DI'].iloc[-1]:\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "\n",
    "    # Ichimoku\n",
    "    if data['close'].iloc[-1] > data['Senkou Span A'].iloc[-1] and data['Tenkan-sen'].iloc[-1] > data['Kijun-sen'].iloc[-1]:\n",
    "        signals.append('bullish')\n",
    "    elif data['close'].iloc[-1] < data['Senkou Span A'].iloc[-1] and data['Tenkan-sen'].iloc[-1] < data['Kijun-sen'].iloc[-1]:\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "\n",
    "    # RSI\n",
    "    if data['RSI_14'].iloc[-1] < 30 or data['RSI_14'].iloc[-1] > 50:\n",
    "        signals.append('bullish')\n",
    "    elif data['RSI_14'].iloc[-1] > 30 or data['RSI_14'].iloc[-1] < 50:\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "\n",
    "    # MACD\n",
    "    if data['MACD'].iloc[-1] > data['MACD_Signal'].iloc[-1]:\n",
    "        signals.append('bullish')\n",
    "    elif data['MACD'].iloc[-1] < data['MACD_Signal'].iloc[-1]:\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "\n",
    "    # Stochastic Oscillator\n",
    "    if data['Stoch_K'].iloc[-1] > data['Stoch_D'].iloc[-1] and data['Stoch_K'].iloc[-1] < 20:\n",
    "        signals.append('bullish')\n",
    "    elif data['Stoch_K'].iloc[-1] < data['Stoch_D'].iloc[-1] and data['Stoch_K'].iloc[-1] > 20:\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "\n",
    "    # OBV\n",
    "    if data['OBV'].iloc[-1] > data['OBV'].iloc[-2]:  # OBV rising\n",
    "        signals.append('bullish')\n",
    "    elif data['OBV'].iloc[-1] < data['OBV'].iloc[-2]:\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "\n",
    "    # VWAP\n",
    "    if data['close'].iloc[-1] > data['VWAP'].iloc[-1]:\n",
    "        signals.append('bullish')\n",
    "    elif data['close'].iloc[-1] < data['VWAP'].iloc[-1]:\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "\n",
    "    # Bollinger Bands\n",
    "    if data['close'].iloc[-1] < data['BB_Lower'].iloc[-1]:  # Touching lower band\n",
    "        signals.append('bullish')\n",
    "    elif data['close'].iloc[-1] > data['BB_Upper'].iloc[-1]:  # Touching upper band\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "\n",
    "    # ATR (Volatility Expansion)\n",
    "    if data['ATR_14'].iloc[-1] > data['ATR_14'].iloc[-2]:  # ATR increasing\n",
    "        signals.append('bullish')\n",
    "    elif data['ATR_14'].iloc[-1] < data['ATR_14'].iloc[-2]:\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "\n",
    "    # Keltner Channel\n",
    "    if data['close'].iloc[-1] > data['Keltner_Upper'].iloc[-1]:\n",
    "        signals.append('bullish')\n",
    "    elif data['close'].iloc[-1] < data['Keltner_Lower'].iloc[-1]:\n",
    "        signals.append('bearish')\n",
    "    else:\n",
    "        signals.append('neutral')\n",
    "        \n",
    "\n",
    "    # Count bullish and bearish signals\n",
    "    bullish_count = signals.count('bullish')\n",
    "    bearish_count = signals.count('bearish')\n",
    "    for i in range(len(indicators)):\n",
    "        print(indicators[i]+' '+signals[i])\n",
    "    print(bullish_count,bearish_count,len(signals)-bullish_count-bearish_count)\n",
    "    # Final prediction\n",
    "    if bullish_count > bearish_count:\n",
    "        return 'bullish'\n",
    "    elif bearish_count > bullish_count:\n",
    "        return 'bearish'\n",
    "    else:\n",
    "        return 'neutral'  # When there's a tie or no clear trend\n",
    "    \n",
    "\n",
    "# Example: Get the final signal for the most recent data\n",
    "signal = get_signal(data)\n",
    "print(f\"Final Prediction: {signal}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TradingModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_layers=3, hidden_units=64):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for _ in range(num_layers):\n",
    "            layers.append(nn.Linear(input_dim, hidden_units))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = hidden_units\n",
    "        layers.append(nn.Linear(hidden_units, 1))  # Predict return\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maml_train(model, tasks, inner_lr, inner_steps, outer_lr, epochs):\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=outer_lr)\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for task in tasks:\n",
    "            # Clone model for inner loop\n",
    "            fast_weights = dict(model.named_parameters())\n",
    "            \n",
    "            # Inner loop adaptation\n",
    "            for _ in range(inner_steps):\n",
    "                loss = compute_loss(task['support'], model, fast_weights)\n",
    "                grads = torch.autograd.grad(loss, fast_weights.values())\n",
    "                fast_weights = {name: param - inner_lr * grad \n",
    "                               for (name, param), grad in zip(fast_weights.items(), grads)}\n",
    "            \n",
    "            # Compute query loss and backprop\n",
    "            query_loss = compute_loss(task['query'], model, fast_weights)\n",
    "            total_loss += query_loss\n",
    "            query_loss.backward()\n",
    "        \n",
    "        # Outer optimization step\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-02-11 13:07:21,511] A new study created in memory with name: no-name-6ff007ee-e3a2-4df7-b834-fef408445eb8\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_16156\\1450247049.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'inner_lr': trial.suggest_loguniform('inner_lr', 1e-5, 1e-2),\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_16156\\1450247049.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'outer_lr': trial.suggest_loguniform('outer_lr', 1e-4, 1e-2),\n",
      "[W 2025-02-11 13:07:21,521] Trial 0 failed with parameters: {'inner_lr': 0.009807532962362663, 'outer_lr': 0.0012354211261741675, 'inner_steps': 5, 'layers': 3, 'neurons': 32} because of the following error: NameError(\"name 'train_tasks' is not defined\").\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_16156\\1450247049.py\", line 13, in objective\n",
      "    maml_train(model, train_tasks, params['inner_lr'], params['inner_steps'], params['outer_lr'], epochs=10)\n",
      "                      ^^^^^^^^^^^\n",
      "NameError: name 'train_tasks' is not defined\n",
      "[W 2025-02-11 13:07:21,524] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_tasks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sharpe\n\u001b[0;32m     17\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[7], line 13\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m      4\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner_lr\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_loguniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner_lr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1e-5\u001b[39m, \u001b[38;5;241m1e-2\u001b[39m),\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mouter_lr\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_loguniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mouter_lr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1e-4\u001b[39m, \u001b[38;5;241m1e-2\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneurons\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneurons\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m128\u001b[39m])\n\u001b[0;32m     10\u001b[0m }\n\u001b[0;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m TradingModel(input_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m, num_layers\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayers\u001b[39m\u001b[38;5;124m'\u001b[39m], hidden_units\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneurons\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 13\u001b[0m maml_train(model, \u001b[43mtrain_tasks\u001b[49m, params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner_lr\u001b[39m\u001b[38;5;124m'\u001b[39m], params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner_steps\u001b[39m\u001b[38;5;124m'\u001b[39m], params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mouter_lr\u001b[39m\u001b[38;5;124m'\u001b[39m], epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     14\u001b[0m sharpe \u001b[38;5;241m=\u001b[39m evaluate(model, val_tasks)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sharpe\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_tasks' is not defined"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'inner_lr': trial.suggest_loguniform('inner_lr', 1e-5, 1e-2),\n",
    "        'outer_lr': trial.suggest_loguniform('outer_lr', 1e-4, 1e-2),\n",
    "        'inner_steps': trial.suggest_int('inner_steps', 1, 5),\n",
    "        'layers': trial.suggest_int('layers', 2, 4),\n",
    "        'neurons': trial.suggest_categorical('neurons', [32, 64, 128])\n",
    "    }\n",
    "    \n",
    "    model = TradingModel(input_dim=12, num_layers=params['layers'], hidden_units=params['neurons'])\n",
    "    maml_train(model, train_tasks, params['inner_lr'], params['inner_steps'], params['outer_lr'], epochs=10)\n",
    "    sharpe = evaluate(model, val_tasks)\n",
    "    return sharpe\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(model, test_tasks):\n",
    "    results = []\n",
    "    for task in test_tasks:\n",
    "        # Adapt model to task\n",
    "        adapted_model = adapt_model(model, task['support'])\n",
    "        \n",
    "        # Generate signals\n",
    "        signals = generate_signals(adapted_model, task['data'])\n",
    "        \n",
    "        # Calculate returns\n",
    "        returns = calculate_returns(signals, task['data']['close'])\n",
    "        \n",
    "        # Compute metrics\n",
    "        results.append({\n",
    "            'sharpe': sharpe_ratio(returns),\n",
    "            'sortino': sortino_ratio(returns),\n",
    "            'max_drawdown': max_drawdown(returns),\n",
    "            'profit_factor': profit_factor(returns)\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe_ratio(returns, risk_free_rate=0):\n",
    "    excess_returns = returns - risk_free_rate\n",
    "    return excess_returns.mean() / excess_returns.std()\n",
    "\n",
    "def sortino_ratio(returns, risk_free_rate=0):\n",
    "    downside_returns = returns[returns < 0]\n",
    "    return (returns.mean() - risk_free_rate) / downside_returns.std()\n",
    "\n",
    "def max_drawdown(returns):\n",
    "    cumulative = (1 + returns).cumprod()\n",
    "    peak = cumulative.expanding(min_periods=1).max()\n",
    "    return (cumulative / peak - 1).min()\n",
    "\n",
    "def profit_factor(returns):\n",
    "    gains = returns[returns > 0].sum()\n",
    "    losses = -returns[returns < 0].sum()\n",
    "    return gains / losses if losses != 0 else float('inf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
